{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1696d75-d304-46ea-bbbc-9108207d4b3f",
   "metadata": {},
   "source": [
    "### IMPORTS AND SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce26c37a-c3bc-4fb6-a473-e446d0c42833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely.wkt\n",
    "import os, warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='warnings.log', level=logging.DEBUG)\n",
    "\n",
    "def custom_warning_handler(message, category, filename, lineno, file=None, line=None):\n",
    "    logging.debug(f'{category.__name__}: {message} in {filename}:{lineno}')\n",
    "\n",
    "warnings.showwarning = custom_warning_handler\n",
    "\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon, MultiPoint\n",
    "import rioxarray as rxr\n",
    "import rasterio\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.cluster import DBSCAN\n",
    "from joblib import dump\n",
    "from shapely import wkt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "SHOW_PLOTS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64bfea-9b4c-4e19-a17f-094c302b4bc0",
   "metadata": {},
   "source": [
    "### FEATURE TOGGLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb07d95-c997-48ba-9bc1-6ed05fd3f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_FLAGS = {\n",
    "    # building coverage\n",
    "    \"building_cov_100m\": True,\n",
    "    \"building_cov_200m\": True,\n",
    "    \"building_cov_500m\": True,\n",
    "\n",
    "    # parks coverage\n",
    "    \"park_cov_1000m\": True,\n",
    "\n",
    "    # new: water coverage\n",
    "    \"water_cov_1000m\": True,\n",
    "\n",
    "    # new: street trees coverage => we can do a \"point->buffer\" approach\n",
    "    \"street_tree_cov_500m\": True,\n",
    "\n",
    "    # distance to city center\n",
    "    \"dist_to_closest_calculated_city_centroid\": False,\n",
    "\n",
    "    # mathematically calculated neighbourhood clustering\n",
    "    \"location_cluster\": True,\n",
    "\n",
    "    # official cluster approach (point-in-polygon with official NTA or neighborhoods)\n",
    "    \"official_cluster\": False,\n",
    "\n",
    "    # census data for population density\n",
    "    \"population_density\": False,\n",
    "\n",
    "    # subway stations data\n",
    "    \"dist_to_closest_subway_station\": False,\n",
    "\n",
    "    # raster-based features\n",
    "    \"lst_value\": True,\n",
    "    \"ndvi_value\": True,\n",
    "    \"ndbi_value\": True,\n",
    "    \"ndwi_value\": True,\n",
    "    \"evi_value\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2dfdb6-4bc0-4695-853a-1690e223feea",
   "metadata": {},
   "source": [
    "### HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4daab130-64be-433b-9b10-57f1d3734a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_fraction(geom, polygon_gdf, radius=50):\n",
    "    \"\"\"\n",
    "    coverage_fraction:\n",
    "      - We do buffer around 'geom' by 'radius'.\n",
    "      - Clip polygon_gdf with that buffer.\n",
    "      - Sum area of clipped polygons / area of buffer => coverage fraction.\n",
    "    \"\"\"\n",
    "    buffer_poly = geom.buffer(radius)\n",
    "    clipped = gpd.clip(polygon_gdf, buffer_poly)\n",
    "    area_polygons = clipped.geometry.area.sum()\n",
    "    area_buffer = buffer_poly.area\n",
    "    return area_polygons / area_buffer if area_buffer > 0 else 0\n",
    "\n",
    "# def building_coverage_fraction(geom, building_gdf, radius=50):\n",
    "#     buffer_poly = geom.buffer(radius)\n",
    "#     clipped = gpd.clip(building_gdf, buffer_poly)\n",
    "#     area_buildings = clipped.geometry.area.sum()\n",
    "#     area_buf = buffer_poly.area\n",
    "#     return area_buildings / area_buf if area_buf > 0 else 0\n",
    "\n",
    "def distance_to_polygons(geom, poly_gdf):\n",
    "    dists = poly_gdf.geometry.distance(geom)\n",
    "    return dists.min() if len(dists)>0 else np.nan\n",
    "\n",
    "def euclidean_distance(x1, y1, x2, y2):\n",
    "    return np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "\n",
    "def extract_raster_value(geom, raster, band_index=1, method=\"nearest\"):\n",
    "    \"\"\"Return the pixel value from raster at geom's location.\"\"\"\n",
    "    x, y = geom.x, geom.y\n",
    "    val = raster.sel(x=x, y=y, band=band_index, method=method).values\n",
    "    return float(val)\n",
    "\n",
    "def point_in_official_cluster(geom, cluster_gdf, id_column=\"NTACode\"):\n",
    "    \"\"\"\n",
    "    If official_cluster is True, we do a point-in-polygon sjoin\n",
    "    with an official neighborhoods or NTA shapefile that has an 'id_column'\n",
    "    representing the area ID.\n",
    "    \"\"\"\n",
    "    pt_gdf = gpd.GeoDataFrame([1], geometry=[geom], crs=cluster_gdf.crs)\n",
    "    joined = gpd.sjoin(pt_gdf, cluster_gdf, how=\"left\", predicate=\"within\")\n",
    "    if len(joined)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return joined[id_column].iloc[0]  # or name field\n",
    "\n",
    "def compute_evi(blue, red, nir, L=1.0, C1=6.0, C2=7.5, G=2.5):\n",
    "    return G * (nir - red) / (nir + C1*red - C2*blue + L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe2cdb4-d674-4380-89e7-47f59c90c474",
   "metadata": {},
   "source": [
    "### LOAD BOROUGH BOUNDARIES, BUILDINGS, WATER, PARKS, TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e76b6bfd-7d16-4de4-af39-7ba6ae4768e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading building footprints, parks, water coverage, street tree CSV...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading building footprints, parks, water coverage, street tree CSV...\")\n",
    "\n",
    "# 3.0 NYC boroughs\n",
    "# gdf_boroughs = gpd.read_file(\"./data/nyc_boroughs.geojson\").to_crs(\"EPSG:2263\")\n",
    "# if \"name\" in gdf_boroughs.columns:\n",
    "#     gdf_boroughs.rename(columns={\"name\":\"BoroName\"}, inplace=True)\n",
    "\n",
    "# 3.1 Building footprints\n",
    "gdf_buildings = gpd.read_file(\"./data/Building_Footprint.kml\").to_crs(\"EPSG:2263\")\n",
    "# gdf_buildings = gpd.sjoin(gdf_buildings, gdf_boroughs, how=\"left\", predicate=\"intersects\")\n",
    "# gdf_buildings = gdf_buildings.dropna(subset=[\"BoroName\"])\n",
    "\n",
    "# 3.2 Parks\n",
    "gdf_parks = gpd.read_file(\"./data/Parks_Properties_20250123.kml\").to_crs(\"EPSG:2263\")\n",
    "\n",
    "# 3.3 Water\n",
    "gdf_water = pd.read_csv(\"./data/NYC_Planimetric_Database__Hydrography_20250123.csv\")\n",
    "gdf_water[\"geometry\"] = gdf_water[\"the_geom\"].apply(wkt.loads)\n",
    "gdf_water = gpd.GeoDataFrame(gdf_water, geometry=\"geometry\", crs=\"EPSG:4326\").to_crs(\"EPSG:2263\")\n",
    "\n",
    "# 3.4 Street Trees from 2015 Census (CSV with lat/lon)\n",
    "df_trees = pd.read_csv(\"./data/2015_Street_Tree_Census_-_Tree_Data_20250205.csv\")\n",
    "# columns: [tree_id, block_id, created_at, tree_dbh, lat, lon, ...] => check real col names\n",
    "# Actually from your snippet: \"latitude\",\"longitude\"\n",
    "df_trees.rename(columns={\"latitude\":\"lat\",\"longitude\":\"lon\"}, inplace=True)\n",
    "# convert to geodf in EPSG:2263\n",
    "gdf_trees_pts = gpd.GeoDataFrame(\n",
    "    df_trees,\n",
    "    geometry=[Point(lon, lat) for lon, lat in zip(df_trees[\"lon\"], df_trees[\"lat\"])],\n",
    "    crs=\"EPSG:4326\"\n",
    ").to_crs(\"EPSG:2263\")\n",
    "\n",
    "# We can create a small buffer around each tree => approximate canopy => polygons:\n",
    "# Maybe scale buffer by DBH? For simplicity, do 2m buffer:\n",
    "gdf_trees_poly = gdf_trees_pts.copy()\n",
    "gdf_trees_poly[\"geometry\"] = gdf_trees_poly.geometry.buffer(2.0)  # 2m radius\n",
    "    \n",
    "# 3.6 Official Cluster Polygons (NTAs or Neighborhoods)\n",
    "# gdf_official_clusters = gpd.read_file(\"./data/2020_NTAs.shp\").to_crs(\"EPSG:2263\")\n",
    "\n",
    "# 3.7 Population Census for population density\n",
    "# gdf_census = gpd.read_file(\"./data/2020 Census Tracts_20250206.geojson\").to_crs(\"EPSG:2263\")\n",
    "\n",
    "# 3.8 Subway stations\n",
    "gdf_stations = gpd.read_file(\"./data/MTA Subway Stations_20250206.geojson\").to_crs(\"EPSG:2263\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18a86b4-5751-409a-83e1-d1a42188324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "df_train = pd.read_csv(\"./data/Training_data_uhi_index 2025-02-04.csv\")\n",
    "gdf_train = gpd.GeoDataFrame(\n",
    "    df_train,\n",
    "    geometry=[Point(lon, lat) for lon, lat in zip(df_train.Longitude, df_train.Latitude)],\n",
    "    crs=\"EPSG:4326\"\n",
    ").to_crs(\"EPSG:2263\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a0c7e95-992b-4fb6-a473-fbf1c86553e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# from shapely.geometry import box\n",
    "\n",
    "# # 1. Extract the total bounds of gdf_train\n",
    "# minx_train, miny_train, maxx_train, maxy_train = gdf_train.total_bounds\n",
    "\n",
    "# # 2. Define a buffer in the same units as your CRS (here, meters)\n",
    "# buffer = 1000  # adjust this value if you need a slightly larger or smaller margin\n",
    "\n",
    "# # 3. Create an expanded bounding box\n",
    "# expanded_bbox = box(minx_train - buffer, \n",
    "#                     miny_train - buffer, \n",
    "#                     maxx_train + buffer, \n",
    "#                     maxy_train + buffer)\n",
    "\n",
    "# # Optional: If you want to see the coordinates of the expanded bounding box:\n",
    "# print(\"Expanded Bounding Box:\", expanded_bbox.bounds)\n",
    "\n",
    "# # 4. Create a sub-dataframe from gdf_buildings 1GB that only contains features intersecting the expanded bbox\n",
    "# gdf_buildings = gdf_buildings[gdf_buildings.geometry.intersects(expanded_bbox)]\n",
    "# gdf_buildings['centroid'] = gdf_buildings.geometry.centroid\n",
    "\n",
    "# # Check the total bounds of the new subset\n",
    "# print(\"Subset Total Bounds:\", gdf_buildings.total_bounds)\n",
    "# print(\"Train Total Bounds:\", gdf_train.total_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7263645-60c4-491b-868c-9ddb51cddb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the centroid of the largest cluster of building points.\n",
    "# coords = np.column_stack([gdf_buildings.centroid.x, gdf_buildings.centroid.y]) # Extract coordinates from centroids\n",
    "\n",
    "# # Cluster building points using DBSCAN\n",
    "# # These parameters are chosen to merge clusters (e.g., Manhattan and Bronx) in NYC.\n",
    "# eps_m = 400   # maximum distance (in meters) to consider two points as neighbors\n",
    "# min_samples = 10  # minimum number of points required to form a cluster\n",
    "# db = DBSCAN(eps=eps_m, min_samples=min_samples).fit(coords)\n",
    "# labels = db.labels_\n",
    "# gdf_buildings['cluster'] = labels\n",
    "\n",
    "# # Determine the largest cluster (ignoring noise, which is labeled -1)\n",
    "# valid_mask = (labels >= 0)\n",
    "# if np.any(valid_mask):\n",
    "#     unique_labels, counts = np.unique(labels[valid_mask], return_counts=True)\n",
    "#     largest_label = unique_labels[np.argmax(counts)]\n",
    "#     in_largest = coords[labels == largest_label]\n",
    "#     if len(in_largest) > 0:\n",
    "#         city_centroid = MultiPoint(in_largest).centroid\n",
    "#     else:\n",
    "#         city_centroid = MultiPoint(coords).centroid\n",
    "# else:\n",
    "#     city_centroid = MultiPoint(coords).centroid\n",
    "\n",
    "# city_x, city_y = city_centroid.x, city_centroid.y\n",
    "# print(f\"Centroid of the largest cluster of buildings in the city x/y: {city_x}, {city_y}\")\n",
    "\n",
    "# if SHOW_PLOTS:\n",
    "#     # Plot all building centroids colored by their cluster labels, and overlay the city centroid\n",
    "#     fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "#     # Scatter plot: Use a colormap (e.g., 'tab20') to distinguish different clusters.\n",
    "#     # Noise points (label -1) will get their own color.\n",
    "#     scatter = ax.scatter(\n",
    "#         coords[:, 0], \n",
    "#         coords[:, 1], \n",
    "#         c=labels, \n",
    "#         cmap='tab20', \n",
    "#         s=10, \n",
    "#         alpha=0.6,\n",
    "#         label=\"Building Centroids\"\n",
    "#     )\n",
    "    \n",
    "#     # Overlay the city centroid as a large red star\n",
    "#     ax.scatter(city_centroid.x, city_centroid.y, color='red', marker='*', s=200, label='City Centroid')\n",
    "    \n",
    "#     ax.set_title(\"Building Clusters and City Centroid\")\n",
    "#     ax.set_xlabel(\"X coordinate\")\n",
    "#     ax.set_ylabel(\"Y coordinate\")\n",
    "#     ax.legend()\n",
    "#     plt.colorbar(scatter, ax=ax, label=\"Cluster Label\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6952906c-17fb-4be8-a162-bf8b8b2b4efb",
   "metadata": {},
   "source": [
    "### LOAD + CHECK RASTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "611e885c-dc06-46a4-8eec-3604537de571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reprojected LST + Indices...\n",
      "LST valid ratio: 1.000\n",
      "Indices valid ratio: 0.998\n",
      "LST raster bounds: (981437.4489166049, 212457.5409991683, 1023088.2146540834, 260009.54459267546)\n",
      "Indices raster bounds: (981462.3462672028, 212512.2857439316, 1023050.6163433915, 259944.0070645472)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading reprojected LST + Indices...\")\n",
    "lst_raster = rxr.open_rasterio(\"Landsat_LST_v4_single_0601_0901.tiff\")\n",
    "lst_raster_2263 = lst_raster.rio.reproject(\"EPSG:2263\")\n",
    "\n",
    "indices_raster = rxr.open_rasterio(\"S2_indices_v4_single_0601_0901.tiff\")\n",
    "indices_raster_2263 = indices_raster.rio.reproject(\"EPSG:2263\")\n",
    "\n",
    "# Check if the rasters actually have valid data\n",
    "ratio_lst = (~lst_raster_2263.isnull()).mean().values\n",
    "ratio_idx = (~indices_raster_2263.isnull()).mean().values\n",
    "print(f\"LST valid ratio: {ratio_lst:.3f}\")\n",
    "print(f\"Indices valid ratio: {ratio_idx:.3f}\")\n",
    "\n",
    "if ratio_lst == 0.0:\n",
    "    print(\"WARNING: LST raster is entirely NaN. Possibly an empty mosaic or over-strict cloud mask!\")\n",
    "if ratio_idx == 0.0:\n",
    "    print(\"WARNING: Indices raster is entirely NaN. Possibly an empty mosaic or over-strict cloud mask!\")\n",
    "\n",
    "print(\"LST raster bounds:\", lst_raster_2263.rio.bounds())\n",
    "print(\"Indices raster bounds:\", indices_raster_2263.rio.bounds())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83160e-a888-4e6c-9903-c915f3c1f23c",
   "metadata": {},
   "source": [
    "### BUILD TRAINING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "002b2d3c-e428-45ee-b56a-d0248cc25852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows: 11269\n",
      "0.00%\n",
      "8.87%\n",
      "17.75%\n",
      "26.62%\n",
      "35.50%\n",
      "44.37%\n",
      "53.24%\n",
      "62.12%\n",
      "70.99%\n",
      "79.87%\n",
      "88.74%\n",
      "97.61%\n",
      "100.00% Done with feature computations.\n",
      "Done attaching columns.\n"
     ]
    }
   ],
   "source": [
    "# Prepare empty arrays for each feature\n",
    "arr_cov_bld_100  = []\n",
    "arr_cov_bld_200  = []\n",
    "arr_cov_bld_500  = []\n",
    "\n",
    "arr_cov_park_1000 = []\n",
    "arr_cov_tree_500  = []\n",
    "arr_cov_water_1000 = []\n",
    "\n",
    "arr_dist_city_centroid = []\n",
    "arr_dist_subway_station = []\n",
    "\n",
    "arr_lst_vals  = []\n",
    "arr_ndvi_vals = []\n",
    "arr_ndbi_vals = []\n",
    "arr_ndwi_vals = []\n",
    "\n",
    "# If you eventually compute location_cluster, official_cluster, population_density,\n",
    "# you'd prepare arrays for them as well. For now we skip them or store 0.\n",
    "\n",
    "total_rows = len(gdf_train)\n",
    "print(f\"total rows: {total_rows}\")\n",
    "\n",
    "for i, row in gdf_train.iterrows():\n",
    "    if i % 1000 == 0:\n",
    "        percent_done = (i / total_rows) * 100\n",
    "        print(f\"{percent_done:.2f}%\")\n",
    "        \n",
    "    geom = row.geometry\n",
    "    \n",
    "    # building coverage\n",
    "    if FEATURE_FLAGS[\"building_cov_100m\"]:\n",
    "        b100 = coverage_fraction(geom, gdf_buildings, 100)\n",
    "    else:\n",
    "        b100 = 0\n",
    "    arr_cov_bld_100.append(b100)\n",
    "\n",
    "    if FEATURE_FLAGS[\"building_cov_200m\"]:\n",
    "        b200 = coverage_fraction(geom, gdf_buildings, 200)\n",
    "    else:\n",
    "        b200 = 0\n",
    "    arr_cov_bld_200.append(b200)\n",
    "\n",
    "    if FEATURE_FLAGS[\"building_cov_500m\"]:\n",
    "        b500 = coverage_fraction(geom, gdf_buildings, 500)\n",
    "    else:\n",
    "        b500 = 0\n",
    "    arr_cov_bld_500.append(b500)\n",
    "\n",
    "    # park coverage\n",
    "    if FEATURE_FLAGS[\"park_cov_1000m\"]:\n",
    "        p1000 = coverage_fraction(geom, gdf_parks, 1000)\n",
    "    else:\n",
    "        p1000 = 0\n",
    "    arr_cov_park_1000.append(p1000)\n",
    "\n",
    "    # street trees coverage\n",
    "    if FEATURE_FLAGS[\"street_tree_cov_500m\"]:\n",
    "        t500 = coverage_fraction(geom, gdf_trees_poly, 500)\n",
    "    else:\n",
    "        t500 = 0\n",
    "    arr_cov_tree_500.append(t500)\n",
    "\n",
    "    # water coverage\n",
    "    if FEATURE_FLAGS[\"water_cov_1000m\"]:\n",
    "        w1000 = coverage_fraction(geom, gdf_water, 1000)\n",
    "    else:\n",
    "        w1000 = 0\n",
    "    arr_cov_water_1000.append(w1000)\n",
    "\n",
    "    # distance to city centroid (calculated)\n",
    "    if FEATURE_FLAGS[\"dist_to_closest_calculated_city_centroid\"]:\n",
    "        d_centroid = euclidean_distance(geom.x, geom.y, city_x, city_y)\n",
    "    else:\n",
    "        d_centroid = None\n",
    "    arr_dist_city_centroid.append(d_centroid)\n",
    "\n",
    "    # distance to nearest subway station\n",
    "    if FEATURE_FLAGS[\"dist_to_closest_subway_station\"]:\n",
    "        dists = gdf_stations.geometry.distance(geom)\n",
    "        dist_min = dists.min() if len(dists) > 0 else 0\n",
    "    else:\n",
    "        dist_min = None\n",
    "    arr_dist_subway_station.append(dist_min)\n",
    "\n",
    "    # LST / NDVI / NDBI / NDWI\n",
    "    if FEATURE_FLAGS[\"lst_value\"]:\n",
    "        lv = extract_raster_value(geom, lst_raster_2263, band_index=1)\n",
    "    else:\n",
    "        lv = 0\n",
    "    arr_lst_vals.append(lv)\n",
    "\n",
    "    if FEATURE_FLAGS[\"ndvi_value\"]:\n",
    "        ndv = extract_raster_value(geom, indices_raster_2263, band_index=1)\n",
    "    else:\n",
    "        ndv = 0\n",
    "    arr_ndvi_vals.append(ndv)\n",
    "\n",
    "    if FEATURE_FLAGS[\"ndbi_value\"]:\n",
    "        ndb = extract_raster_value(geom, indices_raster_2263, band_index=2)\n",
    "    else:\n",
    "        ndb = 0\n",
    "    arr_ndbi_vals.append(ndb)\n",
    "\n",
    "    if FEATURE_FLAGS[\"ndwi_value\"]:\n",
    "        ndw = extract_raster_value(geom, indices_raster_2263, band_index=3)\n",
    "    else:\n",
    "        ndw = 0\n",
    "    arr_ndwi_vals.append(ndw)\n",
    "\n",
    "print(\"100.00% Done with feature computations.\")\n",
    "\n",
    "# Attach columns to gdf_train if the flag is True\n",
    "if FEATURE_FLAGS[\"building_cov_100m\"]:\n",
    "    gdf_train[\"building_cov_100m\"] = arr_cov_bld_100\n",
    "\n",
    "if FEATURE_FLAGS[\"building_cov_200m\"]:\n",
    "    gdf_train[\"building_cov_200m\"] = arr_cov_bld_200\n",
    "\n",
    "if FEATURE_FLAGS[\"building_cov_500m\"]:\n",
    "    gdf_train[\"building_cov_500m\"] = arr_cov_bld_500\n",
    "\n",
    "if FEATURE_FLAGS[\"park_cov_1000m\"]:\n",
    "    gdf_train[\"park_cov_1000m\"] = arr_cov_park_1000\n",
    "\n",
    "if FEATURE_FLAGS[\"street_tree_cov_500m\"]:\n",
    "    gdf_train[\"street_tree_cov_500m\"] = arr_cov_tree_500\n",
    "\n",
    "if FEATURE_FLAGS[\"water_cov_1000m\"]:\n",
    "    gdf_train[\"water_cov_1000m\"] = arr_cov_water_1000\n",
    "\n",
    "if FEATURE_FLAGS[\"dist_to_closest_calculated_city_centroid\"]:\n",
    "    gdf_train[\"dist_to_closest_calculated_city_centroid\"] = arr_dist_city_centroid\n",
    "\n",
    "if FEATURE_FLAGS[\"dist_to_closest_subway_station\"]:\n",
    "    gdf_train[\"dist_to_closest_subway_station\"] = arr_dist_subway_station\n",
    "\n",
    "if FEATURE_FLAGS[\"lst_value\"]:\n",
    "    gdf_train[\"lst_value\"] = arr_lst_vals\n",
    "\n",
    "if FEATURE_FLAGS[\"ndvi_value\"]:\n",
    "    gdf_train[\"ndvi_value\"] = arr_ndvi_vals\n",
    "\n",
    "if FEATURE_FLAGS[\"ndbi_value\"]:\n",
    "    gdf_train[\"ndbi_value\"] = arr_ndbi_vals\n",
    "\n",
    "if FEATURE_FLAGS[\"ndwi_value\"]:\n",
    "    gdf_train[\"ndwi_value\"] = arr_ndwi_vals\n",
    "\n",
    "# optional KMeans\n",
    "if FEATURE_FLAGS[\"location_cluster\"]:\n",
    "    from sklearn.cluster import KMeans\n",
    "    N_CLUSTERS = 10\n",
    "    coords_train = np.column_stack([gdf_train.geometry.x, gdf_train.geometry.y])\n",
    "    kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=RANDOM_SEED, n_init=10).fit(coords_train)\n",
    "    gdf_train[\"location_cluster\"] = kmeans.labels_\n",
    "\n",
    "print(\"Done attaching columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2020a12-1efa-40b4-8166-2fbad78c3a04",
   "metadata": {},
   "source": [
    "### OUTLIER REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9183b86-ce72-457d-b482-f26301104582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capping 112 outliers above Q=0.99 at 1.037\n"
     ]
    }
   ],
   "source": [
    "# E.g. cap y above 99th percentile\n",
    "cap_quantile= 0.99\n",
    "cap_val= gdf_train[\"UHI Index\"].quantile(cap_quantile)\n",
    "mask_out= (gdf_train[\"UHI Index\"]> cap_val)\n",
    "if mask_out.sum()>0:\n",
    "    print(f\"Capping {mask_out.sum()} outliers above Q={cap_quantile} at {cap_val:.3f}\")\n",
    "    gdf_train.loc[mask_out, \"UHI Index\"]= cap_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbf2817-a9ca-451f-94db-1e077e180047",
   "metadata": {},
   "source": [
    "### FINAL FEATURE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c73a2f73-5eaa-42a5-9c02-76d50dfecbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (11269, 11)\n",
      "Feature columns: ['building_cov_100m', 'building_cov_200m', 'building_cov_500m', 'park_cov_1000m', 'street_tree_cov_500m', 'water_cov_1000m', 'lst_value', 'ndvi_value', 'ndbi_value', 'ndwi_value', 'location_cluster']\n"
     ]
    }
   ],
   "source": [
    "feature_cols = []\n",
    "\n",
    "if FEATURE_FLAGS[\"building_cov_100m\"]:\n",
    "    feature_cols.append(\"building_cov_100m\")\n",
    "if FEATURE_FLAGS[\"building_cov_200m\"]:\n",
    "    feature_cols.append(\"building_cov_200m\")\n",
    "if FEATURE_FLAGS[\"building_cov_500m\"]:\n",
    "    feature_cols.append(\"building_cov_500m\")\n",
    "\n",
    "if FEATURE_FLAGS[\"park_cov_1000m\"]:\n",
    "    feature_cols.append(\"park_cov_1000m\")\n",
    "\n",
    "if FEATURE_FLAGS[\"street_tree_cov_500m\"]:\n",
    "    feature_cols.append(\"street_tree_cov_500m\")\n",
    "\n",
    "if FEATURE_FLAGS[\"water_cov_1000m\"]:\n",
    "    feature_cols.append(\"water_cov_1000m\")\n",
    "\n",
    "if FEATURE_FLAGS[\"dist_to_closest_calculated_city_centroid\"]:\n",
    "    feature_cols.append(\"dist_to_closest_calculated_city_centroid\")\n",
    "\n",
    "if FEATURE_FLAGS[\"dist_to_closest_subway_station\"]:\n",
    "    feature_cols.append(\"dist_to_closest_subway_station\")\n",
    "\n",
    "if FEATURE_FLAGS[\"lst_value\"]:\n",
    "    feature_cols.append(\"lst_value\")\n",
    "\n",
    "if FEATURE_FLAGS[\"ndvi_value\"]:\n",
    "    feature_cols.append(\"ndvi_value\")\n",
    "\n",
    "if FEATURE_FLAGS[\"ndbi_value\"]:\n",
    "    feature_cols.append(\"ndbi_value\")\n",
    "\n",
    "if FEATURE_FLAGS[\"ndwi_value\"]:\n",
    "    feature_cols.append(\"ndwi_value\")\n",
    "\n",
    "if FEATURE_FLAGS[\"location_cluster\"]:\n",
    "    feature_cols.append(\"location_cluster\")\n",
    "if FEATURE_FLAGS[\"official_cluster\"]:\n",
    "    feature_cols.append(\"official_cluster\")\n",
    "if FEATURE_FLAGS[\"population_density\"]:\n",
    "    feature_cols.append(\"population_density\")\n",
    "\n",
    "df_train_feat = gdf_train[feature_cols].fillna(0.0)\n",
    "X = df_train_feat.values\n",
    "y = gdf_train[\"UHI Index\"].values\n",
    "\n",
    "print(\"Train shape:\", X.shape)\n",
    "print(\"Feature columns:\", feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a406bb55-f3d0-4c5d-9f7f-f22d3838cb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_cov_100m</th>\n",
       "      <th>building_cov_200m</th>\n",
       "      <th>building_cov_500m</th>\n",
       "      <th>park_cov_1000m</th>\n",
       "      <th>street_tree_cov_500m</th>\n",
       "      <th>water_cov_1000m</th>\n",
       "      <th>lst_value</th>\n",
       "      <th>ndvi_value</th>\n",
       "      <th>ndbi_value</th>\n",
       "      <th>ndwi_value</th>\n",
       "      <th>location_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11269.000000</td>\n",
       "      <td>11269.000000</td>\n",
       "      <td>11269.000000</td>\n",
       "      <td>11269.000000</td>\n",
       "      <td>11269.000000</td>\n",
       "      <td>11269.000000</td>\n",
       "      <td>11269.000000</td>\n",
       "      <td>11269.000000</td>\n",
       "      <td>11269.000000</td>\n",
       "      <td>11269.000000</td>\n",
       "      <td>11269.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.231138</td>\n",
       "      <td>0.307259</td>\n",
       "      <td>0.328751</td>\n",
       "      <td>0.141040</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>40.441024</td>\n",
       "      <td>-0.005381</td>\n",
       "      <td>-0.001932</td>\n",
       "      <td>0.022770</td>\n",
       "      <td>4.277842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.187019</td>\n",
       "      <td>0.189820</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>0.212185</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.073054</td>\n",
       "      <td>2.666938</td>\n",
       "      <td>0.063932</td>\n",
       "      <td>0.067918</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>2.770942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.484185</td>\n",
       "      <td>-0.231795</td>\n",
       "      <td>-0.353383</td>\n",
       "      <td>-0.499395</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.061817</td>\n",
       "      <td>0.172796</td>\n",
       "      <td>0.236984</td>\n",
       "      <td>0.020243</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.067291</td>\n",
       "      <td>-0.037037</td>\n",
       "      <td>-0.037608</td>\n",
       "      <td>0.014394</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.218239</td>\n",
       "      <td>0.315302</td>\n",
       "      <td>0.331127</td>\n",
       "      <td>0.052138</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.663506</td>\n",
       "      <td>-0.019201</td>\n",
       "      <td>-0.003988</td>\n",
       "      <td>0.032028</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.355174</td>\n",
       "      <td>0.439667</td>\n",
       "      <td>0.433307</td>\n",
       "      <td>0.160069</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>42.167435</td>\n",
       "      <td>0.008161</td>\n",
       "      <td>0.031743</td>\n",
       "      <td>0.045154</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.824851</td>\n",
       "      <td>0.679903</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.502626</td>\n",
       "      <td>54.564594</td>\n",
       "      <td>0.562697</td>\n",
       "      <td>0.440744</td>\n",
       "      <td>0.165486</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       building_cov_100m  building_cov_200m  building_cov_500m  \\\n",
       "count       11269.000000       11269.000000       11269.000000   \n",
       "mean            0.231138           0.307259           0.328751   \n",
       "std             0.187019           0.189820           0.164384   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.061817           0.172796           0.236984   \n",
       "50%             0.218239           0.315302           0.331127   \n",
       "75%             0.355174           0.439667           0.433307   \n",
       "max             0.999675           0.824851           0.679903   \n",
       "\n",
       "       park_cov_1000m  street_tree_cov_500m  water_cov_1000m     lst_value  \\\n",
       "count    11269.000000          11269.000000     11269.000000  11269.000000   \n",
       "mean         0.141040              0.001614         0.026786     40.441024   \n",
       "std          0.212185              0.000779         0.073054      2.666938   \n",
       "min          0.000000              0.000000         0.000000     32.484185   \n",
       "25%          0.020243              0.001113         0.000000     39.067291   \n",
       "50%          0.052138              0.001661         0.000000     40.663506   \n",
       "75%          0.160069              0.002149         0.001418     42.167435   \n",
       "max          1.000000              0.003626         0.502626     54.564594   \n",
       "\n",
       "         ndvi_value    ndbi_value    ndwi_value  location_cluster  \n",
       "count  11269.000000  11269.000000  11269.000000      11269.000000  \n",
       "mean      -0.005381     -0.001932      0.022770          4.277842  \n",
       "std        0.063932      0.067918      0.048364          2.770942  \n",
       "min       -0.231795     -0.353383     -0.499395          0.000000  \n",
       "25%       -0.037037     -0.037608      0.014394          2.000000  \n",
       "50%       -0.019201     -0.003988      0.032028          4.000000  \n",
       "75%        0.008161      0.031743      0.045154          7.000000  \n",
       "max        0.562697      0.440744      0.165486          9.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_feat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "689290af-c856-4030-b6c9-804d965c32ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_cov_100m</th>\n",
       "      <th>building_cov_200m</th>\n",
       "      <th>building_cov_500m</th>\n",
       "      <th>park_cov_1000m</th>\n",
       "      <th>street_tree_cov_500m</th>\n",
       "      <th>water_cov_1000m</th>\n",
       "      <th>lst_value</th>\n",
       "      <th>ndvi_value</th>\n",
       "      <th>ndbi_value</th>\n",
       "      <th>ndwi_value</th>\n",
       "      <th>location_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295823</td>\n",
       "      <td>0.460293</td>\n",
       "      <td>0.442002</td>\n",
       "      <td>0.022438</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.091780</td>\n",
       "      <td>-0.023052</td>\n",
       "      <td>0.013941</td>\n",
       "      <td>0.031556</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.323297</td>\n",
       "      <td>0.429166</td>\n",
       "      <td>0.432448</td>\n",
       "      <td>0.022526</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.203095</td>\n",
       "      <td>-0.036626</td>\n",
       "      <td>0.026451</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.313570</td>\n",
       "      <td>0.403163</td>\n",
       "      <td>0.428255</td>\n",
       "      <td>0.022573</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.203095</td>\n",
       "      <td>-0.040126</td>\n",
       "      <td>0.057551</td>\n",
       "      <td>0.035192</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.267607</td>\n",
       "      <td>0.397447</td>\n",
       "      <td>0.425799</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.203095</td>\n",
       "      <td>-0.022312</td>\n",
       "      <td>0.063714</td>\n",
       "      <td>0.036385</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.215741</td>\n",
       "      <td>0.415295</td>\n",
       "      <td>0.426592</td>\n",
       "      <td>0.022220</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.203095</td>\n",
       "      <td>-0.038647</td>\n",
       "      <td>0.055567</td>\n",
       "      <td>0.034371</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11264</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057350</td>\n",
       "      <td>34.890471</td>\n",
       "      <td>0.028827</td>\n",
       "      <td>-0.023243</td>\n",
       "      <td>-0.000817</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11265</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059504</td>\n",
       "      <td>34.890471</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>-0.028651</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11266</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063221</td>\n",
       "      <td>34.890471</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>-0.028651</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11267</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>34.890471</td>\n",
       "      <td>0.048808</td>\n",
       "      <td>-0.048659</td>\n",
       "      <td>-0.018743</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11268</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.902456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066893</td>\n",
       "      <td>34.890471</td>\n",
       "      <td>0.048808</td>\n",
       "      <td>-0.048659</td>\n",
       "      <td>-0.018743</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11269 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       building_cov_100m  building_cov_200m  building_cov_500m  \\\n",
       "0               0.295823           0.460293           0.442002   \n",
       "1               0.323297           0.429166           0.432448   \n",
       "2               0.313570           0.403163           0.428255   \n",
       "3               0.267607           0.397447           0.425799   \n",
       "4               0.215741           0.415295           0.426592   \n",
       "...                  ...                ...                ...   \n",
       "11264           0.000000           0.000000           0.000000   \n",
       "11265           0.000000           0.000000           0.000000   \n",
       "11266           0.000000           0.000000           0.000000   \n",
       "11267           0.000000           0.000000           0.000000   \n",
       "11268           0.000000           0.000000           0.000000   \n",
       "\n",
       "       park_cov_1000m  street_tree_cov_500m  water_cov_1000m  lst_value  \\\n",
       "0            0.022438              0.001908         0.000000  44.091780   \n",
       "1            0.022526              0.001918         0.000000  43.203095   \n",
       "2            0.022573              0.001901         0.000000  43.203095   \n",
       "3            0.022469              0.001871         0.000000  43.203095   \n",
       "4            0.022220              0.001791         0.000000  43.203095   \n",
       "...               ...                   ...              ...        ...   \n",
       "11264        0.901596              0.000000         0.057350  34.890471   \n",
       "11265        0.901045              0.000000         0.059504  34.890471   \n",
       "11266        0.901269              0.000000         0.063221  34.890471   \n",
       "11267        0.901956              0.000000         0.065068  34.890471   \n",
       "11268        0.902456              0.000000         0.066893  34.890471   \n",
       "\n",
       "       ndvi_value  ndbi_value  ndwi_value  location_cluster  \n",
       "0       -0.023052    0.013941    0.031556                 3  \n",
       "1       -0.036626    0.026451    0.045455                 3  \n",
       "2       -0.040126    0.057551    0.035192                 3  \n",
       "3       -0.022312    0.063714    0.036385                 3  \n",
       "4       -0.038647    0.055567    0.034371                 3  \n",
       "...           ...         ...         ...               ...  \n",
       "11264    0.028827   -0.023243   -0.000817                 2  \n",
       "11265    0.051500   -0.028651   -0.016411                 2  \n",
       "11266    0.051500   -0.028651   -0.016411                 2  \n",
       "11267    0.048808   -0.048659   -0.018743                 2  \n",
       "11268    0.048808   -0.048659   -0.018743                 2  \n",
       "\n",
       "[11269 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0f03940-ee53-4b35-b855-b90ba8d19556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>datetime</th>\n",
       "      <th>UHI Index</th>\n",
       "      <th>geometry</th>\n",
       "      <th>building_cov_100m</th>\n",
       "      <th>building_cov_200m</th>\n",
       "      <th>building_cov_500m</th>\n",
       "      <th>park_cov_1000m</th>\n",
       "      <th>street_tree_cov_500m</th>\n",
       "      <th>water_cov_1000m</th>\n",
       "      <th>lst_value</th>\n",
       "      <th>ndvi_value</th>\n",
       "      <th>ndbi_value</th>\n",
       "      <th>ndwi_value</th>\n",
       "      <th>location_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.919037</td>\n",
       "      <td>40.814292</td>\n",
       "      <td>24-07-2021 15:53</td>\n",
       "      <td>1.034616</td>\n",
       "      <td>POINT (1006661.089 235955.883)</td>\n",
       "      <td>0.295823</td>\n",
       "      <td>0.460293</td>\n",
       "      <td>0.442002</td>\n",
       "      <td>0.022438</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.091780</td>\n",
       "      <td>-0.023052</td>\n",
       "      <td>0.013941</td>\n",
       "      <td>0.031556</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.918978</td>\n",
       "      <td>40.814365</td>\n",
       "      <td>24-07-2021 15:53</td>\n",
       "      <td>1.028125</td>\n",
       "      <td>POINT (1006677.213 235982.615)</td>\n",
       "      <td>0.323297</td>\n",
       "      <td>0.429166</td>\n",
       "      <td>0.432448</td>\n",
       "      <td>0.022526</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.203095</td>\n",
       "      <td>-0.036626</td>\n",
       "      <td>0.026451</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-73.918927</td>\n",
       "      <td>40.814433</td>\n",
       "      <td>24-07-2021 15:53</td>\n",
       "      <td>1.028125</td>\n",
       "      <td>POINT (1006691.49 236007.523)</td>\n",
       "      <td>0.313570</td>\n",
       "      <td>0.403163</td>\n",
       "      <td>0.428255</td>\n",
       "      <td>0.022573</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.203095</td>\n",
       "      <td>-0.040126</td>\n",
       "      <td>0.057551</td>\n",
       "      <td>0.035192</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.918875</td>\n",
       "      <td>40.814500</td>\n",
       "      <td>24-07-2021 15:53</td>\n",
       "      <td>1.025961</td>\n",
       "      <td>POINT (1006705.77 236031.826)</td>\n",
       "      <td>0.267607</td>\n",
       "      <td>0.397447</td>\n",
       "      <td>0.425799</td>\n",
       "      <td>0.022469</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.203095</td>\n",
       "      <td>-0.022312</td>\n",
       "      <td>0.063714</td>\n",
       "      <td>0.036385</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.918827</td>\n",
       "      <td>40.814560</td>\n",
       "      <td>24-07-2021 15:53</td>\n",
       "      <td>1.025961</td>\n",
       "      <td>POINT (1006719.128 236053.699)</td>\n",
       "      <td>0.215741</td>\n",
       "      <td>0.415295</td>\n",
       "      <td>0.426592</td>\n",
       "      <td>0.022220</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.203095</td>\n",
       "      <td>-0.038647</td>\n",
       "      <td>0.055567</td>\n",
       "      <td>0.034371</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11264</th>\n",
       "      <td>-73.957050</td>\n",
       "      <td>40.790333</td>\n",
       "      <td>24-07-2021 15:59</td>\n",
       "      <td>0.972470</td>\n",
       "      <td>POINT (996143.074 227219.577)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057350</td>\n",
       "      <td>34.890471</td>\n",
       "      <td>0.028827</td>\n",
       "      <td>-0.023243</td>\n",
       "      <td>-0.000817</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11265</th>\n",
       "      <td>-73.957063</td>\n",
       "      <td>40.790308</td>\n",
       "      <td>24-07-2021 15:59</td>\n",
       "      <td>0.972470</td>\n",
       "      <td>POINT (996139.388 227210.467)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059504</td>\n",
       "      <td>34.890471</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>-0.028651</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11266</th>\n",
       "      <td>-73.957093</td>\n",
       "      <td>40.790270</td>\n",
       "      <td>24-07-2021 15:59</td>\n",
       "      <td>0.981124</td>\n",
       "      <td>POINT (996131.087 227196.498)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063221</td>\n",
       "      <td>34.890471</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>-0.028651</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11267</th>\n",
       "      <td>-73.957112</td>\n",
       "      <td>40.790253</td>\n",
       "      <td>24-07-2021 15:59</td>\n",
       "      <td>0.981245</td>\n",
       "      <td>POINT (996126.012 227190.422)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>34.890471</td>\n",
       "      <td>0.048808</td>\n",
       "      <td>-0.048659</td>\n",
       "      <td>-0.018743</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11268</th>\n",
       "      <td>-73.957128</td>\n",
       "      <td>40.790237</td>\n",
       "      <td>24-07-2021 15:59</td>\n",
       "      <td>0.983408</td>\n",
       "      <td>POINT (996121.402 227184.35)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.902456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066893</td>\n",
       "      <td>34.890471</td>\n",
       "      <td>0.048808</td>\n",
       "      <td>-0.048659</td>\n",
       "      <td>-0.018743</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11269 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Longitude   Latitude          datetime  UHI Index  \\\n",
       "0     -73.919037  40.814292  24-07-2021 15:53   1.034616   \n",
       "1     -73.918978  40.814365  24-07-2021 15:53   1.028125   \n",
       "2     -73.918927  40.814433  24-07-2021 15:53   1.028125   \n",
       "3     -73.918875  40.814500  24-07-2021 15:53   1.025961   \n",
       "4     -73.918827  40.814560  24-07-2021 15:53   1.025961   \n",
       "...          ...        ...               ...        ...   \n",
       "11264 -73.957050  40.790333  24-07-2021 15:59   0.972470   \n",
       "11265 -73.957063  40.790308  24-07-2021 15:59   0.972470   \n",
       "11266 -73.957093  40.790270  24-07-2021 15:59   0.981124   \n",
       "11267 -73.957112  40.790253  24-07-2021 15:59   0.981245   \n",
       "11268 -73.957128  40.790237  24-07-2021 15:59   0.983408   \n",
       "\n",
       "                             geometry  building_cov_100m  building_cov_200m  \\\n",
       "0      POINT (1006661.089 235955.883)           0.295823           0.460293   \n",
       "1      POINT (1006677.213 235982.615)           0.323297           0.429166   \n",
       "2       POINT (1006691.49 236007.523)           0.313570           0.403163   \n",
       "3       POINT (1006705.77 236031.826)           0.267607           0.397447   \n",
       "4      POINT (1006719.128 236053.699)           0.215741           0.415295   \n",
       "...                               ...                ...                ...   \n",
       "11264   POINT (996143.074 227219.577)           0.000000           0.000000   \n",
       "11265   POINT (996139.388 227210.467)           0.000000           0.000000   \n",
       "11266   POINT (996131.087 227196.498)           0.000000           0.000000   \n",
       "11267   POINT (996126.012 227190.422)           0.000000           0.000000   \n",
       "11268    POINT (996121.402 227184.35)           0.000000           0.000000   \n",
       "\n",
       "       building_cov_500m  park_cov_1000m  street_tree_cov_500m  \\\n",
       "0               0.442002        0.022438              0.001908   \n",
       "1               0.432448        0.022526              0.001918   \n",
       "2               0.428255        0.022573              0.001901   \n",
       "3               0.425799        0.022469              0.001871   \n",
       "4               0.426592        0.022220              0.001791   \n",
       "...                  ...             ...                   ...   \n",
       "11264           0.000000        0.901596              0.000000   \n",
       "11265           0.000000        0.901045              0.000000   \n",
       "11266           0.000000        0.901269              0.000000   \n",
       "11267           0.000000        0.901956              0.000000   \n",
       "11268           0.000000        0.902456              0.000000   \n",
       "\n",
       "       water_cov_1000m  lst_value  ndvi_value  ndbi_value  ndwi_value  \\\n",
       "0             0.000000  44.091780   -0.023052    0.013941    0.031556   \n",
       "1             0.000000  43.203095   -0.036626    0.026451    0.045455   \n",
       "2             0.000000  43.203095   -0.040126    0.057551    0.035192   \n",
       "3             0.000000  43.203095   -0.022312    0.063714    0.036385   \n",
       "4             0.000000  43.203095   -0.038647    0.055567    0.034371   \n",
       "...                ...        ...         ...         ...         ...   \n",
       "11264         0.057350  34.890471    0.028827   -0.023243   -0.000817   \n",
       "11265         0.059504  34.890471    0.051500   -0.028651   -0.016411   \n",
       "11266         0.063221  34.890471    0.051500   -0.028651   -0.016411   \n",
       "11267         0.065068  34.890471    0.048808   -0.048659   -0.018743   \n",
       "11268         0.066893  34.890471    0.048808   -0.048659   -0.018743   \n",
       "\n",
       "       location_cluster  \n",
       "0                     3  \n",
       "1                     3  \n",
       "2                     3  \n",
       "3                     3  \n",
       "4                     3  \n",
       "...                 ...  \n",
       "11264                 2  \n",
       "11265                 2  \n",
       "11266                 2  \n",
       "11267                 2  \n",
       "11268                 2  \n",
       "\n",
       "[11269 rows x 16 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f216e236-38bd-4d5f-a090-fc263396544d",
   "metadata": {},
   "source": [
    "### DEFINE STRATIFIED CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b327326e-7313-42f5-adbe-d0656c6ef1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stratified_bins(target, n_bins=10):\n",
    "    \"\"\"Bin the continuous target into discrete intervals for use in 'StratifiedKFold'.\"\"\"\n",
    "    # pd.qcut => quantile-based discretization\n",
    "    bins = pd.qcut(target, q=n_bins, duplicates=\"drop\")  # If duplicates occur, drop them\n",
    "    return bins.astype(str)  # Convert to string labels\n",
    "\n",
    "K_FOLDS = 10\n",
    "\n",
    "y_bins = make_stratified_bins(y, n_bins=10)\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "# kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75bda76a-4300-41b2-a859-b1f3acd94841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions and parameter grids\n",
    "models_and_params = {\n",
    "    \"KNeighbors\": (\n",
    "        KNeighborsRegressor(),\n",
    "        {\n",
    "            \"n_neighbors\": [2, 3, 4, 5, 6],\n",
    "            \"weights\": [\"uniform\", \"distance\"],\n",
    "            \"p\": [1, 2, 3, 4],\n",
    "            \"algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            \"leaf_size\": [10, 20, 30, 40],\n",
    "            \"metric\": ['minkowski', 'euclidean', 'manhattan', 'chebyshev'],\n",
    "        }\n",
    "    ),\n",
    "    \"LightGBM\": (\n",
    "        lgb.LGBMRegressor(random_state=RANDOM_SEED, device='gpu', verbose=-1),\n",
    "        {\n",
    "            \"n_estimators\": [200, 300, 400, 500],\n",
    "            \"max_depth\": [-1, 10, 20, 30],\n",
    "            \"learning_rate\": [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "            \"subsample\": [0.5, 0.6, 0.7, 0.8],\n",
    "            \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9],\n",
    "            \"boosting_type\": [\"gbdt\", \"dart\", \"rf\"],\n",
    "            \"num_leaves\": [15, 31, 63],\n",
    "            \"reg_alpha\": [0, 0.1, 1],\n",
    "            \"reg_lambda\": [1.0, 2.0, 0.5],\n",
    "        }\n",
    "    ),\n",
    "    \"CatBoost\": (\n",
    "        CatBoostRegressor(silent=True, random_state=RANDOM_SEED, task_type=\"GPU\", devices='0'),\n",
    "        {\n",
    "            \"iterations\": [200, 300, 400, 500],\n",
    "            \"max_depth\": [None, 5, 10, 15, 20],\n",
    "            \"learning_rate\": [0.1, 0.15, 0.2, 0.25],\n",
    "            \"random_strength\": [1, 2, 3, 4],\n",
    "        }\n",
    "    ),\n",
    "    \"HistGradientBoosting\": (\n",
    "        HistGradientBoostingRegressor(random_state=RANDOM_SEED),\n",
    "        {\n",
    "            \"max_iter\": [200, 300, 400, 500],\n",
    "            \"learning_rate\": [0.001, 0.01, 0.05, 0.1],\n",
    "            \"max_depth\": [None, 10, 20, 30],\n",
    "            \"max_leaf_nodes\": [15, 31, 63],\n",
    "            \"l2_regularization\": [0.0, 0.1, 1.0],\n",
    "            # \"loss\": [\"squared_error\", \"absolute_error\", \"gamma\", \"poisson\", \"quantile\"],\n",
    "            \"quantile\": [0.1, 0.5, 0.8, 0.9, 0.95],\n",
    "            \"min_samples_leaf\": [10, 20, 40],\n",
    "            \"warm_start\": [True, False],\n",
    "        }\n",
    "    ),\n",
    "    \"DecisionTree\": (\n",
    "        DecisionTreeRegressor(random_state=RANDOM_SEED),\n",
    "        {\n",
    "            # \"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "            \"splitter\": [\"best\", \"random\"],\n",
    "            \"max_depth\": [None, 10, 20, 30],\n",
    "            \"min_samples_leaf\": [1, 2, 3],\n",
    "        }\n",
    "    ),\n",
    "    \"RandomForest\": (\n",
    "        RandomForestRegressor(random_state=RANDOM_SEED),\n",
    "        {\n",
    "            \"n_estimators\": [100, 400, 500, 600],\n",
    "            # \"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "            \"max_depth\": [None, 10, 20, 30],\n",
    "            \"min_samples_leaf\": [1, 2, 3],\n",
    "            \"min_samples_split\": [2, 3, 4, 5],\n",
    "            \"max_features\": [1.0, \"sqrt\", \"log2\", 0.5],\n",
    "            \"bootstrap\": [False, True],\n",
    "            \"oob_score\": [False, True],   # only valid if bootstrap=True\n",
    "        }\n",
    "    ),\n",
    "    \"ExtraTrees\":(\n",
    "        ExtraTreesRegressor(random_state=RANDOM_SEED),\n",
    "        {\n",
    "            \"n_estimators\": [100, 200, 300, 400],\n",
    "            # \"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "            \"max_depth\": [None, 20, 25, 30, 35],\n",
    "            \"min_samples_split\": [4, 6, 8, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 3],\n",
    "            \"max_features\": [1.0, \"sqrt\", \"log2\", 0.5],\n",
    "            \"ccp_alpha\": [0.0, 0.001, 0.01],\n",
    "            \"bootstrap\": [False, True],\n",
    "            \"oob_score\": [False, True],   # only valid if bootstrap=True\n",
    "        }\n",
    "    ),\n",
    "    \"XGBoost\":(\n",
    "        xgb.XGBRegressor(random_state=RANDOM_SEED, use_label_encoder=False, eval_metric=\"rmse\", tree_method=\"gpu_hist\", predictor=\"gpu_predictor\"),\n",
    "        {\n",
    "            \"n_estimators\": [80, 100, 150, 200, 300],\n",
    "            \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "            \"max_depth\": [None, 5, 10, 15, 20],\n",
    "            \"booster\": [\"gbtree\", \"dart\"],\n",
    "            \"gamma\": [0, 0.1, 1],\n",
    "            \"reg_alpha\": [0, 0.1, 1],\n",
    "            \"reg_lambda\": [0.5, 1.0, 2.0, 5.0],\n",
    "            \"subsample\": [0.6, 0.7, 0.8, 0.9],\n",
    "            \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9],\n",
    "            # \"tree_method\": [\"auto\", \"hist\", \"approx\"],\n",
    "            \"tree_method\": [\"gpu_hist\"],\n",
    "        }\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c60c60b9-dcc8-4934-a4b7-7b3d0b392551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Searching KNeighbors ===\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV 1/10] END algorithm=ball_tree, leaf_size=20, metric=euclidean, n_neighbors=4, p=3, weights=uniform;, score=0.842 total time=   0.0s\n",
      "[CV 2/10] END algorithm=ball_tree, leaf_size=20, metric=euclidean, n_neighbors=4, p=3, weights=uniform;, score=0.827 total time=   0.0s\n",
      "[CV 3/10] END algorithm=ball_tree, leaf_size=20, metric=euclidean, n_neighbors=4, p=3, weights=uniform;, score=0.840 total time=   0.0s\n",
      "[CV 4/10] END algorithm=ball_tree, leaf_size=20, metric=euclidean, n_neighbors=4, p=3, weights=uniform;, score=0.830 total time=   0.0s\n",
      "[CV 5/10] END algorithm=ball_tree, leaf_size=20, metric=euclidean, n_neighbors=4, p=3, weights=uniform;, score=0.838 total time=   0.0s\n",
      "[CV 6/10] END algorithm=ball_tree, leaf_size=20, metric=euclidean, n_neighbors=4, p=3, weights=uniform;, score=0.850 total time=   0.0s\n",
      "[CV 7/10] END algorithm=ball_tree, leaf_size=20, metric=euclidean, n_neighbors=4, p=3, weights=uniform;, score=0.845 total time=   0.0s\n",
      "[CV 8/10] END algorithm=ball_tree, leaf_size=20, metric=euclidean, n_neighbors=4, p=3, weights=uniform;, score=0.844 total time=   0.0s\n",
      "[CV 9/10] END algorithm=ball_tree, leaf_size=20, metric=euclidean, n_neighbors=4, p=3, weights=uniform;, score=0.840 total time=   0.0s\n",
      "[CV 10/10] END algorithm=ball_tree, leaf_size=20, metric=euclidean, n_neighbors=4, p=3, weights=uniform;, score=0.844 total time=   0.0s\n",
      "[CV 1/10] END algorithm=kd_tree, leaf_size=10, metric=minkowski, n_neighbors=3, p=4, weights=uniform;, score=0.844 total time=   0.0s\n",
      "[CV 2/10] END algorithm=kd_tree, leaf_size=10, metric=minkowski, n_neighbors=3, p=4, weights=uniform;, score=0.819 total time=   0.0s\n",
      "[CV 3/10] END algorithm=kd_tree, leaf_size=10, metric=minkowski, n_neighbors=3, p=4, weights=uniform;, score=0.842 total time=   0.0s\n",
      "[CV 4/10] END algorithm=kd_tree, leaf_size=10, metric=minkowski, n_neighbors=3, p=4, weights=uniform;, score=0.837 total time=   0.0s\n",
      "[CV 5/10] END algorithm=kd_tree, leaf_size=10, metric=minkowski, n_neighbors=3, p=4, weights=uniform;, score=0.835 total time=   0.0s\n",
      "[CV 6/10] END algorithm=kd_tree, leaf_size=10, metric=minkowski, n_neighbors=3, p=4, weights=uniform;, score=0.854 total time=   0.0s\n",
      "[CV 7/10] END algorithm=kd_tree, leaf_size=10, metric=minkowski, n_neighbors=3, p=4, weights=uniform;, score=0.849 total time=   0.0s\n",
      "[CV 8/10] END algorithm=kd_tree, leaf_size=10, metric=minkowski, n_neighbors=3, p=4, weights=uniform;, score=0.855 total time=   0.0s\n",
      "[CV 9/10] END algorithm=kd_tree, leaf_size=10, metric=minkowski, n_neighbors=3, p=4, weights=uniform;, score=0.847 total time=   0.0s\n",
      "[CV 10/10] END algorithm=kd_tree, leaf_size=10, metric=minkowski, n_neighbors=3, p=4, weights=uniform;, score=0.849 total time=   0.0s\n",
      "[CV 1/10] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=3, p=2, weights=uniform;, score=0.872 total time=   0.0s\n",
      "[CV 2/10] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=3, p=2, weights=uniform;, score=0.852 total time=   0.0s\n",
      "[CV 3/10] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=3, p=2, weights=uniform;, score=0.870 total time=   0.0s\n",
      "[CV 4/10] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=3, p=2, weights=uniform;, score=0.859 total time=   0.0s\n",
      "[CV 5/10] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=3, p=2, weights=uniform;, score=0.860 total time=   0.0s\n",
      "[CV 6/10] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=3, p=2, weights=uniform;, score=0.874 total time=   0.0s\n",
      "[CV 7/10] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=3, p=2, weights=uniform;, score=0.872 total time=   0.0s\n",
      "[CV 8/10] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=3, p=2, weights=uniform;, score=0.880 total time=   0.0s\n",
      "[CV 9/10] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=3, p=2, weights=uniform;, score=0.868 total time=   0.0s\n",
      "[CV 10/10] END algorithm=ball_tree, leaf_size=40, metric=minkowski, n_neighbors=3, p=2, weights=uniform;, score=0.871 total time=   0.0s\n",
      "[CV 1/10] END algorithm=ball_tree, leaf_size=30, metric=chebyshev, n_neighbors=3, p=4, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 2/10] END algorithm=ball_tree, leaf_size=30, metric=chebyshev, n_neighbors=3, p=4, weights=distance;, score=0.852 total time=   0.0s\n",
      "[CV 3/10] END algorithm=ball_tree, leaf_size=30, metric=chebyshev, n_neighbors=3, p=4, weights=distance;, score=0.880 total time=   0.0s\n",
      "[CV 4/10] END algorithm=ball_tree, leaf_size=30, metric=chebyshev, n_neighbors=3, p=4, weights=distance;, score=0.878 total time=   0.0s\n",
      "[CV 5/10] END algorithm=ball_tree, leaf_size=30, metric=chebyshev, n_neighbors=3, p=4, weights=distance;, score=0.860 total time=   0.0s\n",
      "[CV 6/10] END algorithm=ball_tree, leaf_size=30, metric=chebyshev, n_neighbors=3, p=4, weights=distance;, score=0.875 total time=   0.0s\n",
      "[CV 7/10] END algorithm=ball_tree, leaf_size=30, metric=chebyshev, n_neighbors=3, p=4, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 8/10] END algorithm=ball_tree, leaf_size=30, metric=chebyshev, n_neighbors=3, p=4, weights=distance;, score=0.885 total time=   0.0s\n",
      "[CV 9/10] END algorithm=ball_tree, leaf_size=30, metric=chebyshev, n_neighbors=3, p=4, weights=distance;, score=0.884 total time=   0.0s\n",
      "[CV 10/10] END algorithm=ball_tree, leaf_size=30, metric=chebyshev, n_neighbors=3, p=4, weights=distance;, score=0.876 total time=   0.0s\n",
      "[CV 1/10] END algorithm=kd_tree, leaf_size=30, metric=minkowski, n_neighbors=6, p=4, weights=uniform;, score=0.763 total time=   0.0s\n",
      "[CV 2/10] END algorithm=kd_tree, leaf_size=30, metric=minkowski, n_neighbors=6, p=4, weights=uniform;, score=0.761 total time=   0.0s\n",
      "[CV 3/10] END algorithm=kd_tree, leaf_size=30, metric=minkowski, n_neighbors=6, p=4, weights=uniform;, score=0.767 total time=   0.0s\n",
      "[CV 4/10] END algorithm=kd_tree, leaf_size=30, metric=minkowski, n_neighbors=6, p=4, weights=uniform;, score=0.747 total time=   0.0s\n",
      "[CV 5/10] END algorithm=kd_tree, leaf_size=30, metric=minkowski, n_neighbors=6, p=4, weights=uniform;, score=0.754 total time=   0.0s\n",
      "[CV 6/10] END algorithm=kd_tree, leaf_size=30, metric=minkowski, n_neighbors=6, p=4, weights=uniform;, score=0.781 total time=   0.0s\n",
      "[CV 7/10] END algorithm=kd_tree, leaf_size=30, metric=minkowski, n_neighbors=6, p=4, weights=uniform;, score=0.761 total time=   0.0s\n",
      "[CV 8/10] END algorithm=kd_tree, leaf_size=30, metric=minkowski, n_neighbors=6, p=4, weights=uniform;, score=0.770 total time=   0.0s\n",
      "[CV 9/10] END algorithm=kd_tree, leaf_size=30, metric=minkowski, n_neighbors=6, p=4, weights=uniform;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END algorithm=kd_tree, leaf_size=30, metric=minkowski, n_neighbors=6, p=4, weights=uniform;, score=0.765 total time=   0.0s\n",
      "\n",
      "=== Searching LightGBM ===\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV 1/10] END boosting_type=gbdt, colsample_bytree=0.7, learning_rate=0.2, max_depth=-1, n_estimators=400, num_leaves=15, reg_alpha=1, reg_lambda=1.0, subsample=0.8;, score=0.613 total time=   0.1s\n",
      "[CV 2/10] END boosting_type=gbdt, colsample_bytree=0.7, learning_rate=0.2, max_depth=-1, n_estimators=400, num_leaves=15, reg_alpha=1, reg_lambda=1.0, subsample=0.8;, score=0.628 total time=   0.1s\n",
      "[CV 3/10] END boosting_type=gbdt, colsample_bytree=0.7, learning_rate=0.2, max_depth=-1, n_estimators=400, num_leaves=15, reg_alpha=1, reg_lambda=1.0, subsample=0.8;, score=0.634 total time=   0.1s\n",
      "[CV 4/10] END boosting_type=gbdt, colsample_bytree=0.7, learning_rate=0.2, max_depth=-1, n_estimators=400, num_leaves=15, reg_alpha=1, reg_lambda=1.0, subsample=0.8;, score=0.587 total time=   0.1s\n",
      "[CV 5/10] END boosting_type=gbdt, colsample_bytree=0.7, learning_rate=0.2, max_depth=-1, n_estimators=400, num_leaves=15, reg_alpha=1, reg_lambda=1.0, subsample=0.8;, score=0.634 total time=   0.1s\n",
      "[CV 6/10] END boosting_type=gbdt, colsample_bytree=0.7, learning_rate=0.2, max_depth=-1, n_estimators=400, num_leaves=15, reg_alpha=1, reg_lambda=1.0, subsample=0.8;, score=0.630 total time=   0.1s\n",
      "[CV 7/10] END boosting_type=gbdt, colsample_bytree=0.7, learning_rate=0.2, max_depth=-1, n_estimators=400, num_leaves=15, reg_alpha=1, reg_lambda=1.0, subsample=0.8;, score=0.608 total time=   0.1s\n",
      "[CV 8/10] END boosting_type=gbdt, colsample_bytree=0.7, learning_rate=0.2, max_depth=-1, n_estimators=400, num_leaves=15, reg_alpha=1, reg_lambda=1.0, subsample=0.8;, score=0.618 total time=   0.1s\n",
      "[CV 9/10] END boosting_type=gbdt, colsample_bytree=0.7, learning_rate=0.2, max_depth=-1, n_estimators=400, num_leaves=15, reg_alpha=1, reg_lambda=1.0, subsample=0.8;, score=0.602 total time=   0.1s\n",
      "[CV 10/10] END boosting_type=gbdt, colsample_bytree=0.7, learning_rate=0.2, max_depth=-1, n_estimators=400, num_leaves=15, reg_alpha=1, reg_lambda=1.0, subsample=0.8;, score=0.606 total time=   0.1s\n",
      "[CV 1/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.595 total time=   0.9s\n",
      "[CV 2/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.623 total time=   0.9s\n",
      "[CV 3/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.624 total time=   0.8s\n",
      "[CV 4/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.579 total time=   0.8s\n",
      "[CV 5/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.621 total time=   0.8s\n",
      "[CV 6/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.630 total time=   0.8s\n",
      "[CV 7/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.599 total time=   0.8s\n",
      "[CV 8/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.619 total time=   0.8s\n",
      "[CV 9/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.593 total time=   0.8s\n",
      "[CV 10/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, num_leaves=63, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.611 total time=   0.8s\n",
      "[CV 1/10] END boosting_type=rf, colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, num_leaves=15, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.417 total time=   0.4s\n",
      "[CV 2/10] END boosting_type=rf, colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, num_leaves=15, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.452 total time=   0.4s\n",
      "[CV 3/10] END boosting_type=rf, colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, num_leaves=15, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.444 total time=   0.5s\n",
      "[CV 4/10] END boosting_type=rf, colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, num_leaves=15, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.412 total time=   0.4s\n",
      "[CV 5/10] END boosting_type=rf, colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, num_leaves=15, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.441 total time=   0.4s\n",
      "[CV 6/10] END boosting_type=rf, colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, num_leaves=15, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.459 total time=   0.5s\n",
      "[CV 7/10] END boosting_type=rf, colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, num_leaves=15, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.413 total time=   0.4s\n",
      "[CV 8/10] END boosting_type=rf, colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, num_leaves=15, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.446 total time=   0.5s\n",
      "[CV 9/10] END boosting_type=rf, colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, num_leaves=15, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.425 total time=   0.4s\n",
      "[CV 10/10] END boosting_type=rf, colsample_bytree=0.6, learning_rate=0.2, max_depth=10, n_estimators=500, num_leaves=15, reg_alpha=1, reg_lambda=0.5, subsample=0.5;, score=0.442 total time=   0.4s\n",
      "[CV 1/10] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, n_estimators=200, num_leaves=15, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7;, score=-4243.694 total time=   0.2s\n",
      "[CV 2/10] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, n_estimators=200, num_leaves=15, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7;, score=-4266.551 total time=   0.2s\n",
      "[CV 3/10] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, n_estimators=200, num_leaves=15, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7;, score=-2666.166 total time=   0.2s\n",
      "[CV 4/10] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, n_estimators=200, num_leaves=15, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7;, score=-2603.367 total time=   0.1s\n",
      "[CV 5/10] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, n_estimators=200, num_leaves=15, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7;, score=-2504.799 total time=   0.1s\n",
      "[CV 6/10] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, n_estimators=200, num_leaves=15, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7;, score=-4231.106 total time=   0.2s\n",
      "[CV 7/10] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, n_estimators=200, num_leaves=15, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7;, score=-4247.948 total time=   0.1s\n",
      "[CV 8/10] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, n_estimators=200, num_leaves=15, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7;, score=-5389.282 total time=   0.1s\n",
      "[CV 9/10] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, n_estimators=200, num_leaves=15, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7;, score=-4168.181 total time=   0.1s\n",
      "[CV 10/10] END boosting_type=dart, colsample_bytree=0.8, learning_rate=0.05, max_depth=30, n_estimators=200, num_leaves=15, reg_alpha=0.1, reg_lambda=0.5, subsample=0.7;, score=-4254.860 total time=   0.1s\n",
      "[CV 1/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.15, max_depth=20, n_estimators=400, num_leaves=15, reg_alpha=0, reg_lambda=1.0, subsample=0.6;, score=0.864 total time=   0.3s\n",
      "[CV 2/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.15, max_depth=20, n_estimators=400, num_leaves=15, reg_alpha=0, reg_lambda=1.0, subsample=0.6;, score=0.869 total time=   0.3s\n",
      "[CV 3/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.15, max_depth=20, n_estimators=400, num_leaves=15, reg_alpha=0, reg_lambda=1.0, subsample=0.6;, score=0.875 total time=   0.3s\n",
      "[CV 4/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.15, max_depth=20, n_estimators=400, num_leaves=15, reg_alpha=0, reg_lambda=1.0, subsample=0.6;, score=0.855 total time=   0.3s\n",
      "[CV 5/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.15, max_depth=20, n_estimators=400, num_leaves=15, reg_alpha=0, reg_lambda=1.0, subsample=0.6;, score=0.867 total time=   0.4s\n",
      "[CV 6/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.15, max_depth=20, n_estimators=400, num_leaves=15, reg_alpha=0, reg_lambda=1.0, subsample=0.6;, score=0.873 total time=   0.4s\n",
      "[CV 7/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.15, max_depth=20, n_estimators=400, num_leaves=15, reg_alpha=0, reg_lambda=1.0, subsample=0.6;, score=0.871 total time=   0.3s\n",
      "[CV 8/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.15, max_depth=20, n_estimators=400, num_leaves=15, reg_alpha=0, reg_lambda=1.0, subsample=0.6;, score=0.869 total time=   0.3s\n",
      "[CV 9/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.15, max_depth=20, n_estimators=400, num_leaves=15, reg_alpha=0, reg_lambda=1.0, subsample=0.6;, score=0.859 total time=   0.3s\n",
      "[CV 10/10] END boosting_type=gbdt, colsample_bytree=0.6, learning_rate=0.15, max_depth=20, n_estimators=400, num_leaves=15, reg_alpha=0, reg_lambda=1.0, subsample=0.6;, score=0.862 total time=   0.3s\n",
      "\n",
      "=== Searching CatBoost ===\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV 1/10] END iterations=400, learning_rate=0.1, max_depth=5, random_strength=4;, score=0.786 total time=   0.5s\n",
      "[CV 2/10] END iterations=400, learning_rate=0.1, max_depth=5, random_strength=4;, score=0.802 total time=   0.5s\n",
      "[CV 3/10] END iterations=400, learning_rate=0.1, max_depth=5, random_strength=4;, score=0.811 total time=   0.6s\n",
      "[CV 4/10] END iterations=400, learning_rate=0.1, max_depth=5, random_strength=4;, score=0.783 total time=   0.5s\n",
      "[CV 5/10] END iterations=400, learning_rate=0.1, max_depth=5, random_strength=4;, score=0.798 total time=   0.6s\n",
      "[CV 6/10] END iterations=400, learning_rate=0.1, max_depth=5, random_strength=4;, score=0.809 total time=   0.5s\n",
      "[CV 7/10] END iterations=400, learning_rate=0.1, max_depth=5, random_strength=4;, score=0.800 total time=   0.5s\n",
      "[CV 8/10] END iterations=400, learning_rate=0.1, max_depth=5, random_strength=4;, score=0.797 total time=   0.5s\n",
      "[CV 9/10] END iterations=400, learning_rate=0.1, max_depth=5, random_strength=4;, score=0.781 total time=   0.5s\n",
      "[CV 10/10] END iterations=400, learning_rate=0.1, max_depth=5, random_strength=4;, score=0.790 total time=   0.5s\n",
      "[CV 1/10] END iterations=400, learning_rate=0.25, max_depth=10, random_strength=3;, score=0.923 total time=   1.7s\n",
      "[CV 2/10] END iterations=400, learning_rate=0.25, max_depth=10, random_strength=3;, score=0.921 total time=   1.7s\n",
      "[CV 3/10] END iterations=400, learning_rate=0.25, max_depth=10, random_strength=3;, score=0.923 total time=   1.7s\n",
      "[CV 4/10] END iterations=400, learning_rate=0.25, max_depth=10, random_strength=3;, score=0.918 total time=   1.7s\n",
      "[CV 5/10] END iterations=400, learning_rate=0.25, max_depth=10, random_strength=3;, score=0.925 total time=   1.8s\n",
      "[CV 6/10] END iterations=400, learning_rate=0.25, max_depth=10, random_strength=3;, score=0.927 total time=   1.7s\n",
      "[CV 7/10] END iterations=400, learning_rate=0.25, max_depth=10, random_strength=3;, score=0.928 total time=   1.7s\n",
      "[CV 8/10] END iterations=400, learning_rate=0.25, max_depth=10, random_strength=3;, score=0.926 total time=   1.7s\n",
      "[CV 9/10] END iterations=400, learning_rate=0.25, max_depth=10, random_strength=3;, score=0.920 total time=   1.7s\n",
      "[CV 10/10] END iterations=400, learning_rate=0.25, max_depth=10, random_strength=3;, score=0.920 total time=   1.7s\n",
      "[CV 1/10] END iterations=200, learning_rate=0.15, max_depth=5, random_strength=2;, score=0.757 total time=   0.4s\n",
      "[CV 2/10] END iterations=200, learning_rate=0.15, max_depth=5, random_strength=2;, score=0.777 total time=   0.4s\n",
      "[CV 3/10] END iterations=200, learning_rate=0.15, max_depth=5, random_strength=2;, score=0.779 total time=   0.4s\n",
      "[CV 4/10] END iterations=200, learning_rate=0.15, max_depth=5, random_strength=2;, score=0.750 total time=   0.4s\n",
      "[CV 5/10] END iterations=200, learning_rate=0.15, max_depth=5, random_strength=2;, score=0.773 total time=   0.4s\n",
      "[CV 6/10] END iterations=200, learning_rate=0.15, max_depth=5, random_strength=2;, score=0.786 total time=   0.4s\n",
      "[CV 7/10] END iterations=200, learning_rate=0.15, max_depth=5, random_strength=2;, score=0.776 total time=   0.4s\n",
      "[CV 8/10] END iterations=200, learning_rate=0.15, max_depth=5, random_strength=2;, score=0.776 total time=   0.4s\n",
      "[CV 9/10] END iterations=200, learning_rate=0.15, max_depth=5, random_strength=2;, score=0.755 total time=   0.4s\n",
      "[CV 10/10] END iterations=200, learning_rate=0.15, max_depth=5, random_strength=2;, score=0.769 total time=   0.4s\n",
      "[CV 1/10] END iterations=200, learning_rate=0.25, max_depth=None, random_strength=4;, score=0.835 total time=   0.4s\n",
      "[CV 2/10] END iterations=200, learning_rate=0.25, max_depth=None, random_strength=4;, score=0.841 total time=   0.4s\n",
      "[CV 3/10] END iterations=200, learning_rate=0.25, max_depth=None, random_strength=4;, score=0.849 total time=   0.4s\n",
      "[CV 4/10] END iterations=200, learning_rate=0.25, max_depth=None, random_strength=4;, score=0.839 total time=   0.4s\n",
      "[CV 5/10] END iterations=200, learning_rate=0.25, max_depth=None, random_strength=4;, score=0.844 total time=   0.4s\n",
      "[CV 6/10] END iterations=200, learning_rate=0.25, max_depth=None, random_strength=4;, score=0.852 total time=   0.5s\n",
      "[CV 7/10] END iterations=200, learning_rate=0.25, max_depth=None, random_strength=4;, score=0.851 total time=   0.4s\n",
      "[CV 8/10] END iterations=200, learning_rate=0.25, max_depth=None, random_strength=4;, score=0.852 total time=   0.4s\n",
      "[CV 9/10] END iterations=200, learning_rate=0.25, max_depth=None, random_strength=4;, score=0.830 total time=   0.4s\n",
      "[CV 10/10] END iterations=200, learning_rate=0.25, max_depth=None, random_strength=4;, score=0.833 total time=   0.4s\n",
      "[CV 1/10] END iterations=200, learning_rate=0.1, max_depth=10, random_strength=2;, score=0.874 total time=   0.9s\n",
      "[CV 2/10] END iterations=200, learning_rate=0.1, max_depth=10, random_strength=2;, score=0.886 total time=   0.9s\n",
      "[CV 3/10] END iterations=200, learning_rate=0.1, max_depth=10, random_strength=2;, score=0.889 total time=   0.9s\n",
      "[CV 4/10] END iterations=200, learning_rate=0.1, max_depth=10, random_strength=2;, score=0.879 total time=   0.9s\n",
      "[CV 5/10] END iterations=200, learning_rate=0.1, max_depth=10, random_strength=2;, score=0.880 total time=   0.9s\n",
      "[CV 6/10] END iterations=200, learning_rate=0.1, max_depth=10, random_strength=2;, score=0.885 total time=   0.9s\n",
      "[CV 7/10] END iterations=200, learning_rate=0.1, max_depth=10, random_strength=2;, score=0.889 total time=   0.9s\n",
      "[CV 8/10] END iterations=200, learning_rate=0.1, max_depth=10, random_strength=2;, score=0.888 total time=   0.9s\n",
      "[CV 9/10] END iterations=200, learning_rate=0.1, max_depth=10, random_strength=2;, score=0.868 total time=   0.9s\n",
      "[CV 10/10] END iterations=200, learning_rate=0.1, max_depth=10, random_strength=2;, score=0.885 total time=   0.9s\n",
      "\n",
      "=== Searching HistGradientBoosting ===\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV 1/10] END l2_regularization=1.0, learning_rate=0.05, max_depth=30, max_iter=500, max_leaf_nodes=31, min_samples_leaf=20, quantile=0.8, warm_start=False;, score=0.859 total time=   0.5s\n",
      "[CV 2/10] END l2_regularization=1.0, learning_rate=0.05, max_depth=30, max_iter=500, max_leaf_nodes=31, min_samples_leaf=20, quantile=0.8, warm_start=False;, score=0.871 total time=   0.5s\n",
      "[CV 3/10] END l2_regularization=1.0, learning_rate=0.05, max_depth=30, max_iter=500, max_leaf_nodes=31, min_samples_leaf=20, quantile=0.8, warm_start=False;, score=0.880 total time=   0.6s\n",
      "[CV 4/10] END l2_regularization=1.0, learning_rate=0.05, max_depth=30, max_iter=500, max_leaf_nodes=31, min_samples_leaf=20, quantile=0.8, warm_start=False;, score=0.859 total time=   0.6s\n",
      "[CV 5/10] END l2_regularization=1.0, learning_rate=0.05, max_depth=30, max_iter=500, max_leaf_nodes=31, min_samples_leaf=20, quantile=0.8, warm_start=False;, score=0.867 total time=   1.0s\n",
      "[CV 6/10] END l2_regularization=1.0, learning_rate=0.05, max_depth=30, max_iter=500, max_leaf_nodes=31, min_samples_leaf=20, quantile=0.8, warm_start=False;, score=0.877 total time=   1.0s\n",
      "[CV 7/10] END l2_regularization=1.0, learning_rate=0.05, max_depth=30, max_iter=500, max_leaf_nodes=31, min_samples_leaf=20, quantile=0.8, warm_start=False;, score=0.870 total time=   1.0s\n",
      "[CV 8/10] END l2_regularization=1.0, learning_rate=0.05, max_depth=30, max_iter=500, max_leaf_nodes=31, min_samples_leaf=20, quantile=0.8, warm_start=False;, score=0.868 total time=   1.0s\n",
      "[CV 9/10] END l2_regularization=1.0, learning_rate=0.05, max_depth=30, max_iter=500, max_leaf_nodes=31, min_samples_leaf=20, quantile=0.8, warm_start=False;, score=0.833 total time=   0.7s\n",
      "[CV 10/10] END l2_regularization=1.0, learning_rate=0.05, max_depth=30, max_iter=500, max_leaf_nodes=31, min_samples_leaf=20, quantile=0.8, warm_start=False;, score=0.873 total time=   0.6s\n",
      "[CV 1/10] END l2_regularization=0.0, learning_rate=0.001, max_depth=20, max_iter=300, max_leaf_nodes=31, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.232 total time=   0.4s\n",
      "[CV 2/10] END l2_regularization=0.0, learning_rate=0.001, max_depth=20, max_iter=300, max_leaf_nodes=31, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.244 total time=   0.4s\n",
      "[CV 3/10] END l2_regularization=0.0, learning_rate=0.001, max_depth=20, max_iter=300, max_leaf_nodes=31, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.239 total time=   0.4s\n",
      "[CV 4/10] END l2_regularization=0.0, learning_rate=0.001, max_depth=20, max_iter=300, max_leaf_nodes=31, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.230 total time=   0.4s\n",
      "[CV 5/10] END l2_regularization=0.0, learning_rate=0.001, max_depth=20, max_iter=300, max_leaf_nodes=31, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.229 total time=   0.4s\n",
      "[CV 6/10] END l2_regularization=0.0, learning_rate=0.001, max_depth=20, max_iter=300, max_leaf_nodes=31, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.249 total time=   0.4s\n",
      "[CV 7/10] END l2_regularization=0.0, learning_rate=0.001, max_depth=20, max_iter=300, max_leaf_nodes=31, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.227 total time=   0.4s\n",
      "[CV 8/10] END l2_regularization=0.0, learning_rate=0.001, max_depth=20, max_iter=300, max_leaf_nodes=31, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.233 total time=   0.4s\n",
      "[CV 9/10] END l2_regularization=0.0, learning_rate=0.001, max_depth=20, max_iter=300, max_leaf_nodes=31, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.234 total time=   0.4s\n",
      "[CV 10/10] END l2_regularization=0.0, learning_rate=0.001, max_depth=20, max_iter=300, max_leaf_nodes=31, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.241 total time=   0.4s\n",
      "[CV 1/10] END l2_regularization=0.0, learning_rate=0.1, max_depth=20, max_iter=500, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.903 total time=   0.6s\n",
      "[CV 2/10] END l2_regularization=0.0, learning_rate=0.1, max_depth=20, max_iter=500, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.908 total time=   0.6s\n",
      "[CV 3/10] END l2_regularization=0.0, learning_rate=0.1, max_depth=20, max_iter=500, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.909 total time=   0.5s\n",
      "[CV 4/10] END l2_regularization=0.0, learning_rate=0.1, max_depth=20, max_iter=500, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.901 total time=   0.6s\n",
      "[CV 5/10] END l2_regularization=0.0, learning_rate=0.1, max_depth=20, max_iter=500, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.903 total time=   0.7s\n",
      "[CV 6/10] END l2_regularization=0.0, learning_rate=0.1, max_depth=20, max_iter=500, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.909 total time=   0.6s\n",
      "[CV 7/10] END l2_regularization=0.0, learning_rate=0.1, max_depth=20, max_iter=500, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.907 total time=   0.6s\n",
      "[CV 8/10] END l2_regularization=0.0, learning_rate=0.1, max_depth=20, max_iter=500, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.910 total time=   0.7s\n",
      "[CV 9/10] END l2_regularization=0.0, learning_rate=0.1, max_depth=20, max_iter=500, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.886 total time=   0.6s\n",
      "[CV 10/10] END l2_regularization=0.0, learning_rate=0.1, max_depth=20, max_iter=500, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.1, warm_start=True;, score=0.901 total time=   0.6s\n",
      "[CV 1/10] END l2_regularization=1.0, learning_rate=0.001, max_depth=10, max_iter=200, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.8, warm_start=True;, score=0.198 total time=   0.5s\n",
      "[CV 2/10] END l2_regularization=1.0, learning_rate=0.001, max_depth=10, max_iter=200, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.8, warm_start=True;, score=0.200 total time=   0.5s\n",
      "[CV 3/10] END l2_regularization=1.0, learning_rate=0.001, max_depth=10, max_iter=200, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.8, warm_start=True;, score=0.198 total time=   0.5s\n",
      "[CV 4/10] END l2_regularization=1.0, learning_rate=0.001, max_depth=10, max_iter=200, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.8, warm_start=True;, score=0.196 total time=   0.5s\n",
      "[CV 5/10] END l2_regularization=1.0, learning_rate=0.001, max_depth=10, max_iter=200, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.8, warm_start=True;, score=0.194 total time=   0.5s\n",
      "[CV 6/10] END l2_regularization=1.0, learning_rate=0.001, max_depth=10, max_iter=200, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.8, warm_start=True;, score=0.209 total time=   0.5s\n",
      "[CV 7/10] END l2_regularization=1.0, learning_rate=0.001, max_depth=10, max_iter=200, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.8, warm_start=True;, score=0.190 total time=   0.5s\n",
      "[CV 8/10] END l2_regularization=1.0, learning_rate=0.001, max_depth=10, max_iter=200, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.8, warm_start=True;, score=0.196 total time=   0.5s\n",
      "[CV 9/10] END l2_regularization=1.0, learning_rate=0.001, max_depth=10, max_iter=200, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.8, warm_start=True;, score=0.198 total time=   0.5s\n",
      "[CV 10/10] END l2_regularization=1.0, learning_rate=0.001, max_depth=10, max_iter=200, max_leaf_nodes=63, min_samples_leaf=40, quantile=0.8, warm_start=True;, score=0.200 total time=   0.5s\n",
      "[CV 1/10] END l2_regularization=0.1, learning_rate=0.1, max_depth=30, max_iter=300, max_leaf_nodes=31, min_samples_leaf=10, quantile=0.8, warm_start=True;, score=0.877 total time=   0.4s\n",
      "[CV 2/10] END l2_regularization=0.1, learning_rate=0.1, max_depth=30, max_iter=300, max_leaf_nodes=31, min_samples_leaf=10, quantile=0.8, warm_start=True;, score=0.887 total time=   0.4s\n",
      "[CV 3/10] END l2_regularization=0.1, learning_rate=0.1, max_depth=30, max_iter=300, max_leaf_nodes=31, min_samples_leaf=10, quantile=0.8, warm_start=True;, score=0.895 total time=   0.4s\n",
      "[CV 4/10] END l2_regularization=0.1, learning_rate=0.1, max_depth=30, max_iter=300, max_leaf_nodes=31, min_samples_leaf=10, quantile=0.8, warm_start=True;, score=0.871 total time=   0.4s\n",
      "[CV 5/10] END l2_regularization=0.1, learning_rate=0.1, max_depth=30, max_iter=300, max_leaf_nodes=31, min_samples_leaf=10, quantile=0.8, warm_start=True;, score=0.885 total time=   0.4s\n",
      "[CV 6/10] END l2_regularization=0.1, learning_rate=0.1, max_depth=30, max_iter=300, max_leaf_nodes=31, min_samples_leaf=10, quantile=0.8, warm_start=True;, score=0.890 total time=   0.4s\n",
      "[CV 7/10] END l2_regularization=0.1, learning_rate=0.1, max_depth=30, max_iter=300, max_leaf_nodes=31, min_samples_leaf=10, quantile=0.8, warm_start=True;, score=0.892 total time=   0.4s\n",
      "[CV 8/10] END l2_regularization=0.1, learning_rate=0.1, max_depth=30, max_iter=300, max_leaf_nodes=31, min_samples_leaf=10, quantile=0.8, warm_start=True;, score=0.885 total time=   0.4s\n",
      "[CV 9/10] END l2_regularization=0.1, learning_rate=0.1, max_depth=30, max_iter=300, max_leaf_nodes=31, min_samples_leaf=10, quantile=0.8, warm_start=True;, score=0.862 total time=   0.3s\n",
      "[CV 10/10] END l2_regularization=0.1, learning_rate=0.1, max_depth=30, max_iter=300, max_leaf_nodes=31, min_samples_leaf=10, quantile=0.8, warm_start=True;, score=0.887 total time=   0.4s\n",
      "\n",
      "=== Searching DecisionTree ===\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV 1/10] END max_depth=10, min_samples_leaf=2, splitter=best;, score=0.749 total time=   0.1s\n",
      "[CV 2/10] END max_depth=10, min_samples_leaf=2, splitter=best;, score=0.702 total time=   0.1s\n",
      "[CV 3/10] END max_depth=10, min_samples_leaf=2, splitter=best;, score=0.748 total time=   0.1s\n",
      "[CV 4/10] END max_depth=10, min_samples_leaf=2, splitter=best;, score=0.724 total time=   0.1s\n",
      "[CV 5/10] END max_depth=10, min_samples_leaf=2, splitter=best;, score=0.714 total time=   0.1s\n",
      "[CV 6/10] END max_depth=10, min_samples_leaf=2, splitter=best;, score=0.727 total time=   0.1s\n",
      "[CV 7/10] END max_depth=10, min_samples_leaf=2, splitter=best;, score=0.730 total time=   0.1s\n",
      "[CV 8/10] END max_depth=10, min_samples_leaf=2, splitter=best;, score=0.711 total time=   0.1s\n",
      "[CV 9/10] END max_depth=10, min_samples_leaf=2, splitter=best;, score=0.695 total time=   0.1s\n",
      "[CV 10/10] END max_depth=10, min_samples_leaf=2, splitter=best;, score=0.729 total time=   0.1s\n",
      "[CV 1/10] END max_depth=20, min_samples_leaf=3, splitter=best;, score=0.872 total time=   0.1s\n",
      "[CV 2/10] END max_depth=20, min_samples_leaf=3, splitter=best;, score=0.835 total time=   0.1s\n",
      "[CV 3/10] END max_depth=20, min_samples_leaf=3, splitter=best;, score=0.822 total time=   0.1s\n",
      "[CV 4/10] END max_depth=20, min_samples_leaf=3, splitter=best;, score=0.820 total time=   0.1s\n",
      "[CV 5/10] END max_depth=20, min_samples_leaf=3, splitter=best;, score=0.826 total time=   0.1s\n",
      "[CV 6/10] END max_depth=20, min_samples_leaf=3, splitter=best;, score=0.817 total time=   0.1s\n",
      "[CV 7/10] END max_depth=20, min_samples_leaf=3, splitter=best;, score=0.834 total time=   0.1s\n",
      "[CV 8/10] END max_depth=20, min_samples_leaf=3, splitter=best;, score=0.818 total time=   0.1s\n",
      "[CV 9/10] END max_depth=20, min_samples_leaf=3, splitter=best;, score=0.793 total time=   0.1s\n",
      "[CV 10/10] END max_depth=20, min_samples_leaf=3, splitter=best;, score=0.822 total time=   0.1s\n",
      "[CV 1/10] END max_depth=None, min_samples_leaf=1, splitter=best;, score=0.854 total time=   0.1s\n",
      "[CV 2/10] END max_depth=None, min_samples_leaf=1, splitter=best;, score=0.839 total time=   0.1s\n",
      "[CV 3/10] END max_depth=None, min_samples_leaf=1, splitter=best;, score=0.827 total time=   0.1s\n",
      "[CV 4/10] END max_depth=None, min_samples_leaf=1, splitter=best;, score=0.816 total time=   0.1s\n",
      "[CV 5/10] END max_depth=None, min_samples_leaf=1, splitter=best;, score=0.832 total time=   0.1s\n",
      "[CV 6/10] END max_depth=None, min_samples_leaf=1, splitter=best;, score=0.819 total time=   0.1s\n",
      "[CV 7/10] END max_depth=None, min_samples_leaf=1, splitter=best;, score=0.820 total time=   0.1s\n",
      "[CV 8/10] END max_depth=None, min_samples_leaf=1, splitter=best;, score=0.785 total time=   0.1s\n",
      "[CV 9/10] END max_depth=None, min_samples_leaf=1, splitter=best;, score=0.807 total time=   0.1s\n",
      "[CV 10/10] END max_depth=None, min_samples_leaf=1, splitter=best;, score=0.842 total time=   0.1s\n",
      "[CV 1/10] END max_depth=30, min_samples_leaf=1, splitter=best;, score=0.859 total time=   0.1s\n",
      "[CV 2/10] END max_depth=30, min_samples_leaf=1, splitter=best;, score=0.844 total time=   0.1s\n",
      "[CV 3/10] END max_depth=30, min_samples_leaf=1, splitter=best;, score=0.832 total time=   0.1s\n",
      "[CV 4/10] END max_depth=30, min_samples_leaf=1, splitter=best;, score=0.810 total time=   0.1s\n",
      "[CV 5/10] END max_depth=30, min_samples_leaf=1, splitter=best;, score=0.828 total time=   0.1s\n",
      "[CV 6/10] END max_depth=30, min_samples_leaf=1, splitter=best;, score=0.824 total time=   0.1s\n",
      "[CV 7/10] END max_depth=30, min_samples_leaf=1, splitter=best;, score=0.820 total time=   0.1s\n",
      "[CV 8/10] END max_depth=30, min_samples_leaf=1, splitter=best;, score=0.806 total time=   0.1s\n",
      "[CV 9/10] END max_depth=30, min_samples_leaf=1, splitter=best;, score=0.807 total time=   0.1s\n",
      "[CV 10/10] END max_depth=30, min_samples_leaf=1, splitter=best;, score=0.839 total time=   0.1s\n",
      "[CV 1/10] END max_depth=10, min_samples_leaf=3, splitter=random;, score=0.633 total time=   0.0s\n",
      "[CV 2/10] END max_depth=10, min_samples_leaf=3, splitter=random;, score=0.636 total time=   0.0s\n",
      "[CV 3/10] END max_depth=10, min_samples_leaf=3, splitter=random;, score=0.641 total time=   0.0s\n",
      "[CV 4/10] END max_depth=10, min_samples_leaf=3, splitter=random;, score=0.594 total time=   0.0s\n",
      "[CV 5/10] END max_depth=10, min_samples_leaf=3, splitter=random;, score=0.643 total time=   0.0s\n",
      "[CV 6/10] END max_depth=10, min_samples_leaf=3, splitter=random;, score=0.658 total time=   0.0s\n",
      "[CV 7/10] END max_depth=10, min_samples_leaf=3, splitter=random;, score=0.673 total time=   0.0s\n",
      "[CV 8/10] END max_depth=10, min_samples_leaf=3, splitter=random;, score=0.628 total time=   0.0s\n",
      "[CV 9/10] END max_depth=10, min_samples_leaf=3, splitter=random;, score=0.597 total time=   0.0s\n",
      "[CV 10/10] END max_depth=10, min_samples_leaf=3, splitter=random;, score=0.641 total time=   0.0s\n",
      "\n",
      "=== Searching RandomForest ===\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV 1/10] END bootstrap=False, max_depth=20, max_features=1.0, min_samples_leaf=3, min_samples_split=5, n_estimators=500, oob_score=False;, score=0.876 total time=  36.7s\n",
      "[CV 2/10] END bootstrap=False, max_depth=20, max_features=1.0, min_samples_leaf=3, min_samples_split=5, n_estimators=500, oob_score=False;, score=0.843 total time=  38.2s\n",
      "[CV 3/10] END bootstrap=False, max_depth=20, max_features=1.0, min_samples_leaf=3, min_samples_split=5, n_estimators=500, oob_score=False;, score=0.830 total time=  37.4s\n",
      "[CV 4/10] END bootstrap=False, max_depth=20, max_features=1.0, min_samples_leaf=3, min_samples_split=5, n_estimators=500, oob_score=False;, score=0.829 total time=  37.1s\n",
      "[CV 5/10] END bootstrap=False, max_depth=20, max_features=1.0, min_samples_leaf=3, min_samples_split=5, n_estimators=500, oob_score=False;, score=0.825 total time=  37.1s\n",
      "[CV 6/10] END bootstrap=False, max_depth=20, max_features=1.0, min_samples_leaf=3, min_samples_split=5, n_estimators=500, oob_score=False;, score=0.825 total time=  37.3s\n",
      "[CV 7/10] END bootstrap=False, max_depth=20, max_features=1.0, min_samples_leaf=3, min_samples_split=5, n_estimators=500, oob_score=False;, score=0.837 total time=  37.4s\n",
      "[CV 8/10] END bootstrap=False, max_depth=20, max_features=1.0, min_samples_leaf=3, min_samples_split=5, n_estimators=500, oob_score=False;, score=0.822 total time=  37.6s\n",
      "[CV 9/10] END bootstrap=False, max_depth=20, max_features=1.0, min_samples_leaf=3, min_samples_split=5, n_estimators=500, oob_score=False;, score=0.801 total time=  36.9s\n",
      "[CV 10/10] END bootstrap=False, max_depth=20, max_features=1.0, min_samples_leaf=3, min_samples_split=5, n_estimators=500, oob_score=False;, score=0.833 total time=  36.9s\n",
      "[CV 1/10] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=600, oob_score=False;, score=0.939 total time=  14.8s\n",
      "[CV 2/10] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=600, oob_score=False;, score=0.937 total time=  14.6s\n",
      "[CV 3/10] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=600, oob_score=False;, score=0.941 total time=  14.5s\n",
      "[CV 4/10] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=600, oob_score=False;, score=0.933 total time=  14.6s\n",
      "[CV 5/10] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=600, oob_score=False;, score=0.933 total time=  14.4s\n",
      "[CV 6/10] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=600, oob_score=False;, score=0.938 total time=  14.5s\n",
      "[CV 7/10] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=600, oob_score=False;, score=0.944 total time=  14.4s\n",
      "[CV 8/10] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=600, oob_score=False;, score=0.935 total time=  14.4s\n",
      "[CV 9/10] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=600, oob_score=False;, score=0.932 total time=  14.5s\n",
      "[CV 10/10] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=600, oob_score=False;, score=0.939 total time=  14.5s\n",
      "[CV 1/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=3, min_samples_split=3, n_estimators=400, oob_score=False;, score=0.937 total time=  14.2s\n",
      "[CV 2/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=3, min_samples_split=3, n_estimators=400, oob_score=False;, score=0.937 total time=  14.3s\n",
      "[CV 3/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=3, min_samples_split=3, n_estimators=400, oob_score=False;, score=0.939 total time=  14.3s\n",
      "[CV 4/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=3, min_samples_split=3, n_estimators=400, oob_score=False;, score=0.935 total time=  14.2s\n",
      "[CV 5/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=3, min_samples_split=3, n_estimators=400, oob_score=False;, score=0.930 total time=  14.3s\n",
      "[CV 6/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=3, min_samples_split=3, n_estimators=400, oob_score=False;, score=0.936 total time=  14.3s\n",
      "[CV 7/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=3, min_samples_split=3, n_estimators=400, oob_score=False;, score=0.942 total time=  14.3s\n",
      "[CV 8/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=3, min_samples_split=3, n_estimators=400, oob_score=False;, score=0.932 total time=  14.6s\n",
      "[CV 9/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=3, min_samples_split=3, n_estimators=400, oob_score=False;, score=0.928 total time=  14.4s\n",
      "[CV 10/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=3, min_samples_split=3, n_estimators=400, oob_score=False;, score=0.938 total time=  14.2s\n",
      "[CV 1/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=600, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 2/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=600, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 3/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=600, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 4/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=600, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 5/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=600, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 6/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=600, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 7/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=600, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 8/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=600, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 9/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=600, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 10/10] END bootstrap=False, max_depth=20, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=600, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 1/10] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600, oob_score=False;, score=0.924 total time=  10.8s\n",
      "[CV 2/10] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600, oob_score=False;, score=0.922 total time=  11.0s\n",
      "[CV 3/10] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600, oob_score=False;, score=0.925 total time=  10.8s\n",
      "[CV 4/10] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600, oob_score=False;, score=0.920 total time=  10.9s\n",
      "[CV 5/10] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600, oob_score=False;, score=0.920 total time=  10.8s\n",
      "[CV 6/10] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600, oob_score=False;, score=0.925 total time=  11.0s\n",
      "[CV 7/10] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600, oob_score=False;, score=0.928 total time=  11.3s\n",
      "[CV 8/10] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600, oob_score=False;, score=0.922 total time=  11.0s\n",
      "[CV 9/10] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600, oob_score=False;, score=0.915 total time=  11.0s\n",
      "[CV 10/10] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=600, oob_score=False;, score=0.924 total time=  11.0s\n",
      "\n",
      "=== Searching ExtraTrees ===\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV 1/10] END bootstrap=True, ccp_alpha=0.0, max_depth=30, max_features=0.5, min_samples_leaf=3, min_samples_split=4, n_estimators=400, oob_score=False;, score=0.868 total time=   1.3s\n",
      "[CV 2/10] END bootstrap=True, ccp_alpha=0.0, max_depth=30, max_features=0.5, min_samples_leaf=3, min_samples_split=4, n_estimators=400, oob_score=False;, score=0.873 total time=   1.3s\n",
      "[CV 3/10] END bootstrap=True, ccp_alpha=0.0, max_depth=30, max_features=0.5, min_samples_leaf=3, min_samples_split=4, n_estimators=400, oob_score=False;, score=0.879 total time=   1.3s\n",
      "[CV 4/10] END bootstrap=True, ccp_alpha=0.0, max_depth=30, max_features=0.5, min_samples_leaf=3, min_samples_split=4, n_estimators=400, oob_score=False;, score=0.872 total time=   1.3s\n",
      "[CV 5/10] END bootstrap=True, ccp_alpha=0.0, max_depth=30, max_features=0.5, min_samples_leaf=3, min_samples_split=4, n_estimators=400, oob_score=False;, score=0.877 total time=   1.3s\n",
      "[CV 6/10] END bootstrap=True, ccp_alpha=0.0, max_depth=30, max_features=0.5, min_samples_leaf=3, min_samples_split=4, n_estimators=400, oob_score=False;, score=0.880 total time=   1.3s\n",
      "[CV 7/10] END bootstrap=True, ccp_alpha=0.0, max_depth=30, max_features=0.5, min_samples_leaf=3, min_samples_split=4, n_estimators=400, oob_score=False;, score=0.882 total time=   1.4s\n",
      "[CV 8/10] END bootstrap=True, ccp_alpha=0.0, max_depth=30, max_features=0.5, min_samples_leaf=3, min_samples_split=4, n_estimators=400, oob_score=False;, score=0.881 total time=   1.3s\n",
      "[CV 9/10] END bootstrap=True, ccp_alpha=0.0, max_depth=30, max_features=0.5, min_samples_leaf=3, min_samples_split=4, n_estimators=400, oob_score=False;, score=0.865 total time=   1.3s\n",
      "[CV 10/10] END bootstrap=True, ccp_alpha=0.0, max_depth=30, max_features=0.5, min_samples_leaf=3, min_samples_split=4, n_estimators=400, oob_score=False;, score=0.877 total time=   1.3s\n",
      "[CV 1/10] END bootstrap=False, ccp_alpha=0.0, max_depth=25, max_features=1.0, min_samples_leaf=3, min_samples_split=10, n_estimators=300, oob_score=False;, score=0.929 total time=   2.2s\n",
      "[CV 2/10] END bootstrap=False, ccp_alpha=0.0, max_depth=25, max_features=1.0, min_samples_leaf=3, min_samples_split=10, n_estimators=300, oob_score=False;, score=0.926 total time=   2.1s\n",
      "[CV 3/10] END bootstrap=False, ccp_alpha=0.0, max_depth=25, max_features=1.0, min_samples_leaf=3, min_samples_split=10, n_estimators=300, oob_score=False;, score=0.933 total time=   2.2s\n",
      "[CV 4/10] END bootstrap=False, ccp_alpha=0.0, max_depth=25, max_features=1.0, min_samples_leaf=3, min_samples_split=10, n_estimators=300, oob_score=False;, score=0.929 total time=   2.1s\n",
      "[CV 5/10] END bootstrap=False, ccp_alpha=0.0, max_depth=25, max_features=1.0, min_samples_leaf=3, min_samples_split=10, n_estimators=300, oob_score=False;, score=0.930 total time=   2.1s\n",
      "[CV 6/10] END bootstrap=False, ccp_alpha=0.0, max_depth=25, max_features=1.0, min_samples_leaf=3, min_samples_split=10, n_estimators=300, oob_score=False;, score=0.929 total time=   2.2s\n",
      "[CV 7/10] END bootstrap=False, ccp_alpha=0.0, max_depth=25, max_features=1.0, min_samples_leaf=3, min_samples_split=10, n_estimators=300, oob_score=False;, score=0.937 total time=   2.2s\n",
      "[CV 8/10] END bootstrap=False, ccp_alpha=0.0, max_depth=25, max_features=1.0, min_samples_leaf=3, min_samples_split=10, n_estimators=300, oob_score=False;, score=0.933 total time=   2.1s\n",
      "[CV 9/10] END bootstrap=False, ccp_alpha=0.0, max_depth=25, max_features=1.0, min_samples_leaf=3, min_samples_split=10, n_estimators=300, oob_score=False;, score=0.921 total time=   2.2s\n",
      "[CV 10/10] END bootstrap=False, ccp_alpha=0.0, max_depth=25, max_features=1.0, min_samples_leaf=3, min_samples_split=10, n_estimators=300, oob_score=False;, score=0.934 total time=   2.1s\n",
      "[CV 1/10] END bootstrap=False, ccp_alpha=0.01, max_depth=35, max_features=1.0, min_samples_leaf=1, min_samples_split=6, n_estimators=400, oob_score=False;, score=-0.000 total time=  11.2s\n",
      "[CV 2/10] END bootstrap=False, ccp_alpha=0.01, max_depth=35, max_features=1.0, min_samples_leaf=1, min_samples_split=6, n_estimators=400, oob_score=False;, score=-0.000 total time=  11.2s\n",
      "[CV 3/10] END bootstrap=False, ccp_alpha=0.01, max_depth=35, max_features=1.0, min_samples_leaf=1, min_samples_split=6, n_estimators=400, oob_score=False;, score=-0.000 total time=  11.1s\n",
      "[CV 4/10] END bootstrap=False, ccp_alpha=0.01, max_depth=35, max_features=1.0, min_samples_leaf=1, min_samples_split=6, n_estimators=400, oob_score=False;, score=-0.000 total time=  11.1s\n",
      "[CV 5/10] END bootstrap=False, ccp_alpha=0.01, max_depth=35, max_features=1.0, min_samples_leaf=1, min_samples_split=6, n_estimators=400, oob_score=False;, score=-0.000 total time=  11.1s\n",
      "[CV 6/10] END bootstrap=False, ccp_alpha=0.01, max_depth=35, max_features=1.0, min_samples_leaf=1, min_samples_split=6, n_estimators=400, oob_score=False;, score=-0.000 total time=  11.1s\n",
      "[CV 7/10] END bootstrap=False, ccp_alpha=0.01, max_depth=35, max_features=1.0, min_samples_leaf=1, min_samples_split=6, n_estimators=400, oob_score=False;, score=-0.000 total time=  11.1s\n",
      "[CV 8/10] END bootstrap=False, ccp_alpha=0.01, max_depth=35, max_features=1.0, min_samples_leaf=1, min_samples_split=6, n_estimators=400, oob_score=False;, score=-0.000 total time=  11.1s\n",
      "[CV 9/10] END bootstrap=False, ccp_alpha=0.01, max_depth=35, max_features=1.0, min_samples_leaf=1, min_samples_split=6, n_estimators=400, oob_score=False;, score=-0.000 total time=  11.1s\n",
      "[CV 10/10] END bootstrap=False, ccp_alpha=0.01, max_depth=35, max_features=1.0, min_samples_leaf=1, min_samples_split=6, n_estimators=400, oob_score=False;, score=-0.000 total time=  11.1s\n",
      "[CV 1/10] END bootstrap=False, ccp_alpha=0.01, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=400, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 2/10] END bootstrap=False, ccp_alpha=0.01, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=400, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 3/10] END bootstrap=False, ccp_alpha=0.01, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=400, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 4/10] END bootstrap=False, ccp_alpha=0.01, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=400, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 5/10] END bootstrap=False, ccp_alpha=0.01, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=400, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 6/10] END bootstrap=False, ccp_alpha=0.01, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=400, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 7/10] END bootstrap=False, ccp_alpha=0.01, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=400, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 8/10] END bootstrap=False, ccp_alpha=0.01, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=400, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 9/10] END bootstrap=False, ccp_alpha=0.01, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=400, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 10/10] END bootstrap=False, ccp_alpha=0.01, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=400, oob_score=True;, score=nan total time=   0.0s\n",
      "[CV 1/10] END bootstrap=True, ccp_alpha=0.01, max_depth=35, max_features=sqrt, min_samples_leaf=2, min_samples_split=8, n_estimators=300, oob_score=False;, score=-0.000 total time=   1.4s\n",
      "[CV 2/10] END bootstrap=True, ccp_alpha=0.01, max_depth=35, max_features=sqrt, min_samples_leaf=2, min_samples_split=8, n_estimators=300, oob_score=False;, score=-0.000 total time=   1.4s\n",
      "[CV 3/10] END bootstrap=True, ccp_alpha=0.01, max_depth=35, max_features=sqrt, min_samples_leaf=2, min_samples_split=8, n_estimators=300, oob_score=False;, score=-0.000 total time=   1.4s\n",
      "[CV 4/10] END bootstrap=True, ccp_alpha=0.01, max_depth=35, max_features=sqrt, min_samples_leaf=2, min_samples_split=8, n_estimators=300, oob_score=False;, score=-0.000 total time=   1.4s\n",
      "[CV 5/10] END bootstrap=True, ccp_alpha=0.01, max_depth=35, max_features=sqrt, min_samples_leaf=2, min_samples_split=8, n_estimators=300, oob_score=False;, score=-0.000 total time=   1.4s\n",
      "[CV 6/10] END bootstrap=True, ccp_alpha=0.01, max_depth=35, max_features=sqrt, min_samples_leaf=2, min_samples_split=8, n_estimators=300, oob_score=False;, score=-0.000 total time=   1.4s\n",
      "[CV 7/10] END bootstrap=True, ccp_alpha=0.01, max_depth=35, max_features=sqrt, min_samples_leaf=2, min_samples_split=8, n_estimators=300, oob_score=False;, score=-0.000 total time=   1.4s\n",
      "[CV 8/10] END bootstrap=True, ccp_alpha=0.01, max_depth=35, max_features=sqrt, min_samples_leaf=2, min_samples_split=8, n_estimators=300, oob_score=False;, score=-0.000 total time=   1.4s\n",
      "[CV 9/10] END bootstrap=True, ccp_alpha=0.01, max_depth=35, max_features=sqrt, min_samples_leaf=2, min_samples_split=8, n_estimators=300, oob_score=False;, score=-0.000 total time=   1.4s\n",
      "[CV 10/10] END bootstrap=True, ccp_alpha=0.01, max_depth=35, max_features=sqrt, min_samples_leaf=2, min_samples_split=8, n_estimators=300, oob_score=False;, score=-0.000 total time=   1.4s\n",
      "\n",
      "=== Searching XGBoost ===\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV 1/10] END booster=gbtree, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=None, n_estimators=300, reg_alpha=0, reg_lambda=0.5, subsample=0.9, tree_method=gpu_hist;, score=0.187 total time=   0.1s\n",
      "[CV 2/10] END booster=gbtree, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=None, n_estimators=300, reg_alpha=0, reg_lambda=0.5, subsample=0.9, tree_method=gpu_hist;, score=0.196 total time=   0.1s\n",
      "[CV 3/10] END booster=gbtree, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=None, n_estimators=300, reg_alpha=0, reg_lambda=0.5, subsample=0.9, tree_method=gpu_hist;, score=0.189 total time=   0.1s\n",
      "[CV 4/10] END booster=gbtree, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=None, n_estimators=300, reg_alpha=0, reg_lambda=0.5, subsample=0.9, tree_method=gpu_hist;, score=0.192 total time=   0.1s\n",
      "[CV 5/10] END booster=gbtree, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=None, n_estimators=300, reg_alpha=0, reg_lambda=0.5, subsample=0.9, tree_method=gpu_hist;, score=0.182 total time=   0.1s\n",
      "[CV 6/10] END booster=gbtree, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=None, n_estimators=300, reg_alpha=0, reg_lambda=0.5, subsample=0.9, tree_method=gpu_hist;, score=0.202 total time=   0.1s\n",
      "[CV 7/10] END booster=gbtree, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=None, n_estimators=300, reg_alpha=0, reg_lambda=0.5, subsample=0.9, tree_method=gpu_hist;, score=0.171 total time=   0.1s\n",
      "[CV 8/10] END booster=gbtree, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=None, n_estimators=300, reg_alpha=0, reg_lambda=0.5, subsample=0.9, tree_method=gpu_hist;, score=0.186 total time=   0.1s\n",
      "[CV 9/10] END booster=gbtree, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=None, n_estimators=300, reg_alpha=0, reg_lambda=0.5, subsample=0.9, tree_method=gpu_hist;, score=0.181 total time=   0.1s\n",
      "[CV 10/10] END booster=gbtree, colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=None, n_estimators=300, reg_alpha=0, reg_lambda=0.5, subsample=0.9, tree_method=gpu_hist;, score=0.190 total time=   0.1s\n",
      "[CV 1/10] END booster=gbtree, colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=150, reg_alpha=1, reg_lambda=5.0, subsample=0.6, tree_method=gpu_hist;, score=0.393 total time=   0.3s\n",
      "[CV 2/10] END booster=gbtree, colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=150, reg_alpha=1, reg_lambda=5.0, subsample=0.6, tree_method=gpu_hist;, score=0.416 total time=   0.3s\n",
      "[CV 3/10] END booster=gbtree, colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=150, reg_alpha=1, reg_lambda=5.0, subsample=0.6, tree_method=gpu_hist;, score=0.408 total time=   0.3s\n",
      "[CV 4/10] END booster=gbtree, colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=150, reg_alpha=1, reg_lambda=5.0, subsample=0.6, tree_method=gpu_hist;, score=0.384 total time=   0.3s\n",
      "[CV 5/10] END booster=gbtree, colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=150, reg_alpha=1, reg_lambda=5.0, subsample=0.6, tree_method=gpu_hist;, score=0.413 total time=   0.3s\n",
      "[CV 6/10] END booster=gbtree, colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=150, reg_alpha=1, reg_lambda=5.0, subsample=0.6, tree_method=gpu_hist;, score=0.417 total time=   0.3s\n",
      "[CV 7/10] END booster=gbtree, colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=150, reg_alpha=1, reg_lambda=5.0, subsample=0.6, tree_method=gpu_hist;, score=0.383 total time=   0.3s\n",
      "[CV 8/10] END booster=gbtree, colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=150, reg_alpha=1, reg_lambda=5.0, subsample=0.6, tree_method=gpu_hist;, score=0.408 total time=   0.3s\n",
      "[CV 9/10] END booster=gbtree, colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=150, reg_alpha=1, reg_lambda=5.0, subsample=0.6, tree_method=gpu_hist;, score=0.392 total time=   0.3s\n",
      "[CV 10/10] END booster=gbtree, colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=150, reg_alpha=1, reg_lambda=5.0, subsample=0.6, tree_method=gpu_hist;, score=0.400 total time=   0.3s\n",
      "[CV 1/10] END booster=dart, colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=None, n_estimators=80, reg_alpha=0.1, reg_lambda=1.0, subsample=0.6, tree_method=gpu_hist;, score=0.689 total time=   0.4s\n",
      "[CV 2/10] END booster=dart, colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=None, n_estimators=80, reg_alpha=0.1, reg_lambda=1.0, subsample=0.6, tree_method=gpu_hist;, score=0.709 total time=   0.4s\n",
      "[CV 3/10] END booster=dart, colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=None, n_estimators=80, reg_alpha=0.1, reg_lambda=1.0, subsample=0.6, tree_method=gpu_hist;, score=0.711 total time=   0.4s\n",
      "[CV 4/10] END booster=dart, colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=None, n_estimators=80, reg_alpha=0.1, reg_lambda=1.0, subsample=0.6, tree_method=gpu_hist;, score=0.678 total time=   0.4s\n",
      "[CV 5/10] END booster=dart, colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=None, n_estimators=80, reg_alpha=0.1, reg_lambda=1.0, subsample=0.6, tree_method=gpu_hist;, score=0.703 total time=   0.5s\n",
      "[CV 6/10] END booster=dart, colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=None, n_estimators=80, reg_alpha=0.1, reg_lambda=1.0, subsample=0.6, tree_method=gpu_hist;, score=0.708 total time=   0.4s\n",
      "[CV 7/10] END booster=dart, colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=None, n_estimators=80, reg_alpha=0.1, reg_lambda=1.0, subsample=0.6, tree_method=gpu_hist;, score=0.699 total time=   0.4s\n",
      "[CV 8/10] END booster=dart, colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=None, n_estimators=80, reg_alpha=0.1, reg_lambda=1.0, subsample=0.6, tree_method=gpu_hist;, score=0.694 total time=   0.5s\n",
      "[CV 9/10] END booster=dart, colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=None, n_estimators=80, reg_alpha=0.1, reg_lambda=1.0, subsample=0.6, tree_method=gpu_hist;, score=0.679 total time=   0.5s\n",
      "[CV 10/10] END booster=dart, colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=None, n_estimators=80, reg_alpha=0.1, reg_lambda=1.0, subsample=0.6, tree_method=gpu_hist;, score=0.700 total time=   0.5s\n",
      "[CV 1/10] END booster=dart, colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.8, tree_method=gpu_hist;, score=0.749 total time=   3.7s\n",
      "[CV 2/10] END booster=dart, colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.8, tree_method=gpu_hist;, score=0.761 total time=   3.6s\n",
      "[CV 3/10] END booster=dart, colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.8, tree_method=gpu_hist;, score=0.758 total time=   3.6s\n",
      "[CV 4/10] END booster=dart, colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.8, tree_method=gpu_hist;, score=0.747 total time=   3.5s\n",
      "[CV 5/10] END booster=dart, colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.8, tree_method=gpu_hist;, score=0.755 total time=   3.7s\n",
      "[CV 6/10] END booster=dart, colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.8, tree_method=gpu_hist;, score=0.759 total time=   3.5s\n",
      "[CV 7/10] END booster=dart, colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.8, tree_method=gpu_hist;, score=0.751 total time=   3.5s\n",
      "[CV 8/10] END booster=dart, colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.8, tree_method=gpu_hist;, score=0.756 total time=   3.5s\n",
      "[CV 9/10] END booster=dart, colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.8, tree_method=gpu_hist;, score=0.736 total time=   3.6s\n",
      "[CV 10/10] END booster=dart, colsample_bytree=0.7, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.8, tree_method=gpu_hist;, score=0.753 total time=   3.5s\n",
      "[CV 1/10] END booster=gbtree, colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=80, reg_alpha=0.1, reg_lambda=2.0, subsample=0.7, tree_method=gpu_hist;, score=0.165 total time=   0.0s\n",
      "[CV 2/10] END booster=gbtree, colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=80, reg_alpha=0.1, reg_lambda=2.0, subsample=0.7, tree_method=gpu_hist;, score=0.153 total time=   0.0s\n",
      "[CV 3/10] END booster=gbtree, colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=80, reg_alpha=0.1, reg_lambda=2.0, subsample=0.7, tree_method=gpu_hist;, score=0.165 total time=   0.0s\n",
      "[CV 4/10] END booster=gbtree, colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=80, reg_alpha=0.1, reg_lambda=2.0, subsample=0.7, tree_method=gpu_hist;, score=0.165 total time=   0.0s\n",
      "[CV 5/10] END booster=gbtree, colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=80, reg_alpha=0.1, reg_lambda=2.0, subsample=0.7, tree_method=gpu_hist;, score=0.151 total time=   0.0s\n",
      "[CV 6/10] END booster=gbtree, colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=80, reg_alpha=0.1, reg_lambda=2.0, subsample=0.7, tree_method=gpu_hist;, score=0.155 total time=   0.0s\n",
      "[CV 7/10] END booster=gbtree, colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=80, reg_alpha=0.1, reg_lambda=2.0, subsample=0.7, tree_method=gpu_hist;, score=0.165 total time=   0.1s\n",
      "[CV 8/10] END booster=gbtree, colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=80, reg_alpha=0.1, reg_lambda=2.0, subsample=0.7, tree_method=gpu_hist;, score=0.167 total time=   0.0s\n",
      "[CV 9/10] END booster=gbtree, colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=80, reg_alpha=0.1, reg_lambda=2.0, subsample=0.7, tree_method=gpu_hist;, score=0.137 total time=   0.0s\n",
      "[CV 10/10] END booster=gbtree, colsample_bytree=0.6, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=80, reg_alpha=0.1, reg_lambda=2.0, subsample=0.7, tree_method=gpu_hist;, score=0.146 total time=   0.0s\n",
      "\n",
      "Final Cross-Val Results:\n",
      "                   Model                                     Best Estimator  \\\n",
      "5          RandomForest  (DecisionTreeRegressor(max_depth=30, max_featu...   \n",
      "6            ExtraTrees  (ExtraTreeRegressor(max_depth=25, min_samples_...   \n",
      "2              CatBoost  <catboost.core.CatBoostRegressor object at 0x7...   \n",
      "3  HistGradientBoosting  HistGradientBoostingRegressor(max_depth=20, ma...   \n",
      "0            KNeighbors  KNeighborsRegressor(algorithm='ball_tree', met...   \n",
      "1              LightGBM  LGBMRegressor(colsample_bytree=0.6, device='gp...   \n",
      "4          DecisionTree  DecisionTreeRegressor(max_depth=30, random_sta...   \n",
      "7               XGBoost  XGBRegressor(base_score=None, booster='dart', ...   \n",
      "\n",
      "   Best Score (CV)                                        Best Params  \n",
      "5         0.937135  {'oob_score': False, 'n_estimators': 600, 'min...  \n",
      "6         0.930140  {'oob_score': False, 'n_estimators': 300, 'min...  \n",
      "2         0.922999  {'random_strength': 3, 'max_depth': 10, 'learn...  \n",
      "3         0.903688  {'warm_start': True, 'quantile': 0.1, 'min_sam...  \n",
      "0         0.872765  {'weights': 'distance', 'p': 4, 'n_neighbors':...  \n",
      "1         0.866530  {'subsample': 0.6, 'reg_lambda': 1.0, 'reg_alp...  \n",
      "4         0.827073  {'splitter': 'best', 'min_samples_leaf': 1, 'm...  \n",
      "7         0.752503  {'tree_method': 'gpu_hist', 'subsample': 0.8, ...  \n"
     ]
    }
   ],
   "source": [
    "N_ITER = 5\n",
    "results = []\n",
    "\n",
    "for model_name, (model, param_grid) in models_and_params.items():\n",
    "    print(f\"\\n=== Searching {model_name} ===\")\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=N_ITER,\n",
    "        cv=list(skf.split(X, y_bins)),\n",
    "        scoring=\"r2\",\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=1,\n",
    "        verbose=3\n",
    "    )\n",
    "    search.fit(X, y)\n",
    "    best_estimator = search.best_estimator_\n",
    "    best_score = search.best_score_\n",
    "    best_params = search.best_params_\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Best Estimator\": best_estimator,\n",
    "        \"Best Score (CV)\": best_score,\n",
    "        \"Best Params\": best_params\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"Best Score (CV)\", ascending=False)\n",
    "print(\"\\nFinal Cross-Val Results:\\n\", results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "018bd501-3c56-42be-a688-c3546e79dea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Estimator</th>\n",
       "      <th>Best Score (CV)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>(DecisionTreeRegressor(max_depth=30, max_featu...</td>\n",
       "      <td>0.937135</td>\n",
       "      <td>{'oob_score': False, 'n_estimators': 600, 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>(ExtraTreeRegressor(max_depth=25, min_samples_...</td>\n",
       "      <td>0.930140</td>\n",
       "      <td>{'oob_score': False, 'n_estimators': 300, 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>&lt;catboost.core.CatBoostRegressor object at 0x7...</td>\n",
       "      <td>0.922999</td>\n",
       "      <td>{'random_strength': 3, 'max_depth': 10, 'learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "      <td>HistGradientBoostingRegressor(max_depth=20, ma...</td>\n",
       "      <td>0.903688</td>\n",
       "      <td>{'warm_start': True, 'quantile': 0.1, 'min_sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>KNeighborsRegressor(algorithm='ball_tree', met...</td>\n",
       "      <td>0.872765</td>\n",
       "      <td>{'weights': 'distance', 'p': 4, 'n_neighbors':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>LGBMRegressor(colsample_bytree=0.6, device='gp...</td>\n",
       "      <td>0.866530</td>\n",
       "      <td>{'subsample': 0.6, 'reg_lambda': 1.0, 'reg_alp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>DecisionTreeRegressor(max_depth=30, random_sta...</td>\n",
       "      <td>0.827073</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 1, 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBRegressor(base_score=None, booster='dart', ...</td>\n",
       "      <td>0.752503</td>\n",
       "      <td>{'tree_method': 'gpu_hist', 'subsample': 0.8, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model                                     Best Estimator  \\\n",
       "5          RandomForest  (DecisionTreeRegressor(max_depth=30, max_featu...   \n",
       "6            ExtraTrees  (ExtraTreeRegressor(max_depth=25, min_samples_...   \n",
       "2              CatBoost  <catboost.core.CatBoostRegressor object at 0x7...   \n",
       "3  HistGradientBoosting  HistGradientBoostingRegressor(max_depth=20, ma...   \n",
       "0            KNeighbors  KNeighborsRegressor(algorithm='ball_tree', met...   \n",
       "1              LightGBM  LGBMRegressor(colsample_bytree=0.6, device='gp...   \n",
       "4          DecisionTree  DecisionTreeRegressor(max_depth=30, random_sta...   \n",
       "7               XGBoost  XGBRegressor(base_score=None, booster='dart', ...   \n",
       "\n",
       "   Best Score (CV)                                        Best Params  \n",
       "5         0.937135  {'oob_score': False, 'n_estimators': 600, 'min...  \n",
       "6         0.930140  {'oob_score': False, 'n_estimators': 300, 'min...  \n",
       "2         0.922999  {'random_strength': 3, 'max_depth': 10, 'learn...  \n",
       "3         0.903688  {'warm_start': True, 'quantile': 0.1, 'min_sam...  \n",
       "0         0.872765  {'weights': 'distance', 'p': 4, 'n_neighbors':...  \n",
       "1         0.866530  {'subsample': 0.6, 'reg_lambda': 1.0, 'reg_alp...  \n",
       "4         0.827073  {'splitter': 'best', 'min_samples_leaf': 1, 'm...  \n",
       "7         0.752503  {'tree_method': 'gpu_hist', 'subsample': 0.8, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_csv('results_df.csv', index=False, sep='|')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a236c4f-6c3d-4bbe-b454-6001ed5ae71b",
   "metadata": {},
   "source": [
    "### VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11add13f-bff5-4cf2-8b1b-554334251d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows: 1040\n",
      "0.00%\n",
      "9.62%\n",
      "19.23%\n",
      "28.85%\n",
      "38.46%\n",
      "48.08%\n",
      "57.69%\n",
      "67.31%\n",
      "76.92%\n",
      "86.54%\n",
      "96.15%\n",
      "100.00% Done with feature computations.\n",
      "Validation shape: (1040, 11)\n",
      "feature_cols: ['building_cov_100m', 'building_cov_200m', 'building_cov_500m', 'park_cov_1000m', 'water_cov_1000m', 'street_tree_cov_500m', 'location_cluster', 'lst_value', 'ndvi_value', 'ndbi_value', 'ndwi_value']\n"
     ]
    }
   ],
   "source": [
    "df_val = pd.read_csv(\"./data/Submission_template_UHI2025-v2.csv\")\n",
    "gdf_val = gpd.GeoDataFrame(\n",
    "    df_val,\n",
    "    geometry=[Point(lon, lat) for lon, lat in zip(df_val.Longitude, df_val.Latitude)],\n",
    "    crs=\"EPSG:4326\"\n",
    ").to_crs(\"EPSG:2263\")\n",
    "\n",
    "# We'll create a dictionary to hold computed values for each feature flag\n",
    "computed_feature_values = {key: [] for key in FEATURE_FLAGS if FEATURE_FLAGS[key]}\n",
    "\n",
    "total_rows = len(gdf_val)\n",
    "print(f\"total rows: {total_rows}\")\n",
    "\n",
    "for idx, row in gdf_val.iterrows():\n",
    "    if idx % 100 == 0:\n",
    "        percent_done = (idx / total_rows) * 100\n",
    "        print(f\"{percent_done:.2f}%\")\n",
    "    \n",
    "    geom = row.geometry\n",
    "    \n",
    "    # 1) building_cov_100m\n",
    "    if FEATURE_FLAGS[\"building_cov_100m\"]:\n",
    "        val_bld_100 = coverage_fraction(geom, gdf_buildings, 100)\n",
    "        computed_feature_values[\"building_cov_100m\"].append(val_bld_100)\n",
    "    \n",
    "    # 2) building_cov_200m\n",
    "    if FEATURE_FLAGS[\"building_cov_200m\"]:\n",
    "        val_bld_200 = coverage_fraction(geom, gdf_buildings, 200)\n",
    "        computed_feature_values[\"building_cov_200m\"].append(val_bld_200)\n",
    "    \n",
    "    # 3) building_cov_500m\n",
    "    if FEATURE_FLAGS[\"building_cov_500m\"]:\n",
    "        val_bld_500 = coverage_fraction(geom, gdf_buildings, 500)\n",
    "        computed_feature_values[\"building_cov_500m\"].append(val_bld_500)\n",
    "    \n",
    "    # 4) park_cov_1000m\n",
    "    if FEATURE_FLAGS[\"park_cov_1000m\"]:\n",
    "        val_park_1000 = coverage_fraction(geom, gdf_parks, 1000)\n",
    "        computed_feature_values[\"park_cov_1000m\"].append(val_park_1000)\n",
    "    \n",
    "    # 5) water_cov_1000m\n",
    "    if FEATURE_FLAGS[\"water_cov_1000m\"]:\n",
    "        val_water_1000 = coverage_fraction(geom, gdf_water, 1000)\n",
    "        computed_feature_values[\"water_cov_1000m\"].append(val_water_1000)\n",
    "    \n",
    "    # 6) street_tree_cov_500m\n",
    "    if FEATURE_FLAGS[\"street_tree_cov_500m\"]:\n",
    "        val_tree_500 = coverage_fraction(geom, gdf_trees_poly, 500)\n",
    "        computed_feature_values[\"street_tree_cov_500m\"].append(val_tree_500)\n",
    "    \n",
    "    # 7) dist_to_closest_calculated_city_centroid\n",
    "    if FEATURE_FLAGS[\"dist_to_closest_calculated_city_centroid\"]:\n",
    "        dcc = euclidean_distance(geom.x, geom.y, city_x, city_y)\n",
    "        computed_feature_values[\"dist_to_closest_calculated_city_centroid\"].append(dcc)\n",
    "    \n",
    "    # 8) dist_to_closest_subway_station\n",
    "    if FEATURE_FLAGS[\"dist_to_closest_subway_station\"]:\n",
    "        dists = gdf_stations.geometry.distance(geom)\n",
    "        dist_min = dists.min() if len(dists) > 0 else 0\n",
    "        computed_feature_values[\"dist_to_closest_subway_station\"].append(dist_min)\n",
    "    \n",
    "    # 9) location_cluster\n",
    "    if FEATURE_FLAGS[\"location_cluster\"]:\n",
    "        # Suppose you have a kmeans object for location\n",
    "        # If not, default to 0\n",
    "        if kmeans is not None:\n",
    "            arr = np.array([[geom.x, geom.y]])\n",
    "            cluster_label = kmeans.predict(arr)[0]\n",
    "        else:\n",
    "            cluster_label = 0\n",
    "        computed_feature_values[\"location_cluster\"].append(cluster_label)\n",
    "    \n",
    "    # 10) lst_value\n",
    "    if FEATURE_FLAGS[\"lst_value\"]:\n",
    "        lv = extract_raster_value(geom, lst_raster_2263, band_index=1)\n",
    "        computed_feature_values[\"lst_value\"].append(lv)\n",
    "    \n",
    "    # 11) ndvi_value\n",
    "    if FEATURE_FLAGS[\"ndvi_value\"]:\n",
    "        ndv = extract_raster_value(geom, indices_raster_2263, band_index=1)\n",
    "        computed_feature_values[\"ndvi_value\"].append(ndv)\n",
    "    \n",
    "    # 12) ndbi_value\n",
    "    if FEATURE_FLAGS[\"ndbi_value\"]:\n",
    "        ndb = extract_raster_value(geom, indices_raster_2263, band_index=2)\n",
    "        computed_feature_values[\"ndbi_value\"].append(ndb)\n",
    "    \n",
    "    # 13) ndwi_value\n",
    "    if FEATURE_FLAGS[\"ndwi_value\"]:\n",
    "        ndw = extract_raster_value(geom, indices_raster_2263, band_index=3)\n",
    "        computed_feature_values[\"ndwi_value\"].append(ndw)\n",
    "    \n",
    "    # 14) evi_value -- if you had raw bands. This is turned off, so we skip unless it's True.\n",
    "\n",
    "print(\"100.00% Done with feature computations.\")\n",
    "\n",
    "# Now attach these columns to df_val\n",
    "for feat_key, feat_values in computed_feature_values.items():\n",
    "    # We create a column named exactly as feat_key\n",
    "    df_val[feat_key] = feat_values\n",
    "\n",
    "# Create a list of feature columns from FEATURE_FLAGS (only those == True)\n",
    "feature_cols = [key for key, val in FEATURE_FLAGS.items() if val]\n",
    "\n",
    "# Build final X_val\n",
    "df_val_feat = df_val[feature_cols].fillna(0.0)\n",
    "X_val = df_val_feat.values\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"feature_cols:\", feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d3a0d36-54be-44ab-a691-20ad6f0b4e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>UHI Index</th>\n",
       "      <th>building_cov_100m</th>\n",
       "      <th>building_cov_200m</th>\n",
       "      <th>building_cov_500m</th>\n",
       "      <th>park_cov_1000m</th>\n",
       "      <th>water_cov_1000m</th>\n",
       "      <th>street_tree_cov_500m</th>\n",
       "      <th>location_cluster</th>\n",
       "      <th>lst_value</th>\n",
       "      <th>ndvi_value</th>\n",
       "      <th>ndbi_value</th>\n",
       "      <th>ndwi_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-73.934816</td>\n",
       "      <td>40.807991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.228639</td>\n",
       "      <td>0.306988</td>\n",
       "      <td>0.326797</td>\n",
       "      <td>0.131451</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>4.245192</td>\n",
       "      <td>40.578069</td>\n",
       "      <td>-0.010139</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>0.026572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.028661</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.183847</td>\n",
       "      <td>0.187521</td>\n",
       "      <td>0.163913</td>\n",
       "      <td>0.199796</td>\n",
       "      <td>0.068922</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>2.591998</td>\n",
       "      <td>2.662403</td>\n",
       "      <td>0.056343</td>\n",
       "      <td>0.066481</td>\n",
       "      <td>0.041292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-73.993163</td>\n",
       "      <td>40.758877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.171207</td>\n",
       "      <td>-0.193109</td>\n",
       "      <td>-0.352174</td>\n",
       "      <td>-0.413428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-73.957030</td>\n",
       "      <td>40.790802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062545</td>\n",
       "      <td>0.175813</td>\n",
       "      <td>0.215039</td>\n",
       "      <td>0.020485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.280917</td>\n",
       "      <td>-0.037819</td>\n",
       "      <td>-0.036624</td>\n",
       "      <td>0.017195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-73.934618</td>\n",
       "      <td>40.809553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214779</td>\n",
       "      <td>0.317390</td>\n",
       "      <td>0.331559</td>\n",
       "      <td>0.050155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.776301</td>\n",
       "      <td>-0.021421</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>0.032663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-73.910655</td>\n",
       "      <td>40.823054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.357297</td>\n",
       "      <td>0.436838</td>\n",
       "      <td>0.434537</td>\n",
       "      <td>0.151146</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>42.246904</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.029413</td>\n",
       "      <td>0.045315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-73.879537</td>\n",
       "      <td>40.859243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.822876</td>\n",
       "      <td>0.674815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502626</td>\n",
       "      <td>0.003548</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>54.564594</td>\n",
       "      <td>0.524535</td>\n",
       "      <td>0.301264</td>\n",
       "      <td>0.143845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Longitude     Latitude  UHI Index  building_cov_100m  \\\n",
       "count  1040.000000  1040.000000        0.0        1040.000000   \n",
       "mean    -73.934816    40.807991        NaN           0.228639   \n",
       "std       0.028661     0.023200        NaN           0.183847   \n",
       "min     -73.993163    40.758877        NaN           0.000000   \n",
       "25%     -73.957030    40.790802        NaN           0.062545   \n",
       "50%     -73.934618    40.809553        NaN           0.214779   \n",
       "75%     -73.910655    40.823054        NaN           0.357297   \n",
       "max     -73.879537    40.859243        NaN           0.998447   \n",
       "\n",
       "       building_cov_200m  building_cov_500m  park_cov_1000m  water_cov_1000m  \\\n",
       "count        1040.000000        1040.000000     1040.000000      1040.000000   \n",
       "mean            0.306988           0.326797        0.131451         0.027108   \n",
       "std             0.187521           0.163913        0.199796         0.068922   \n",
       "min             0.000000           0.000000        0.000000         0.000000   \n",
       "25%             0.175813           0.215039        0.020485         0.000000   \n",
       "50%             0.317390           0.331559        0.050155         0.000000   \n",
       "75%             0.436838           0.434537        0.151146         0.003989   \n",
       "max             0.822876           0.674815        1.000000         0.502626   \n",
       "\n",
       "       street_tree_cov_500m  location_cluster    lst_value   ndvi_value  \\\n",
       "count           1040.000000       1040.000000  1040.000000  1040.000000   \n",
       "mean               0.001580          4.245192    40.578069    -0.010139   \n",
       "std                0.000805          2.591998     2.662403     0.056343   \n",
       "min                0.000000          0.000000    33.171207    -0.193109   \n",
       "25%                0.001006          2.000000    39.280917    -0.037819   \n",
       "50%                0.001600          4.000000    40.776301    -0.021421   \n",
       "75%                0.002139          7.000000    42.246904     0.003323   \n",
       "max                0.003548          9.000000    54.564594     0.524535   \n",
       "\n",
       "        ndbi_value   ndwi_value  \n",
       "count  1040.000000  1040.000000  \n",
       "mean     -0.002524     0.026572  \n",
       "std       0.066481     0.041292  \n",
       "min      -0.352174    -0.413428  \n",
       "25%      -0.036624     0.017195  \n",
       "50%      -0.005110     0.032663  \n",
       "75%       0.029413     0.045315  \n",
       "max       0.301264     0.143845  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62632e63-fed7-488b-857c-880894336c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>UHI Index</th>\n",
       "      <th>building_cov_100m</th>\n",
       "      <th>building_cov_200m</th>\n",
       "      <th>building_cov_500m</th>\n",
       "      <th>park_cov_1000m</th>\n",
       "      <th>water_cov_1000m</th>\n",
       "      <th>street_tree_cov_500m</th>\n",
       "      <th>location_cluster</th>\n",
       "      <th>lst_value</th>\n",
       "      <th>ndvi_value</th>\n",
       "      <th>ndbi_value</th>\n",
       "      <th>ndwi_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.971665</td>\n",
       "      <td>40.788763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.248892</td>\n",
       "      <td>0.417782</td>\n",
       "      <td>0.434283</td>\n",
       "      <td>0.022609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>5</td>\n",
       "      <td>40.178148</td>\n",
       "      <td>-0.051394</td>\n",
       "      <td>-0.025287</td>\n",
       "      <td>0.058137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.971928</td>\n",
       "      <td>40.788875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.167185</td>\n",
       "      <td>0.401631</td>\n",
       "      <td>0.434841</td>\n",
       "      <td>0.023426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>5</td>\n",
       "      <td>40.178148</td>\n",
       "      <td>-0.039764</td>\n",
       "      <td>-0.039936</td>\n",
       "      <td>0.046170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-73.967080</td>\n",
       "      <td>40.789080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685125</td>\n",
       "      <td>0.469204</td>\n",
       "      <td>0.393609</td>\n",
       "      <td>0.402937</td>\n",
       "      <td>0.094989</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>5</td>\n",
       "      <td>38.168352</td>\n",
       "      <td>-0.044698</td>\n",
       "      <td>0.024026</td>\n",
       "      <td>0.049971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.972550</td>\n",
       "      <td>40.789082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.505082</td>\n",
       "      <td>0.524747</td>\n",
       "      <td>0.419828</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>5</td>\n",
       "      <td>40.311450</td>\n",
       "      <td>-0.012213</td>\n",
       "      <td>-0.059256</td>\n",
       "      <td>0.040509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.969697</td>\n",
       "      <td>40.787953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.576894</td>\n",
       "      <td>0.712504</td>\n",
       "      <td>0.645928</td>\n",
       "      <td>0.161423</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>5</td>\n",
       "      <td>38.130754</td>\n",
       "      <td>-0.025760</td>\n",
       "      <td>-0.075313</td>\n",
       "      <td>0.039932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>-73.919388</td>\n",
       "      <td>40.813803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.374859</td>\n",
       "      <td>0.371426</td>\n",
       "      <td>0.425470</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>3</td>\n",
       "      <td>44.901851</td>\n",
       "      <td>-0.076566</td>\n",
       "      <td>0.301264</td>\n",
       "      <td>0.040039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>-73.931033</td>\n",
       "      <td>40.833178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119606</td>\n",
       "      <td>0.250616</td>\n",
       "      <td>0.235188</td>\n",
       "      <td>0.024506</td>\n",
       "      <td>0.110873</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>6</td>\n",
       "      <td>39.904706</td>\n",
       "      <td>-0.018511</td>\n",
       "      <td>-0.066043</td>\n",
       "      <td>0.035125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>-73.934647</td>\n",
       "      <td>40.854542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.215837</td>\n",
       "      <td>0.468919</td>\n",
       "      <td>0.400809</td>\n",
       "      <td>0.026099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>9</td>\n",
       "      <td>41.237734</td>\n",
       "      <td>0.072678</td>\n",
       "      <td>-0.054582</td>\n",
       "      <td>-0.068365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>-73.917223</td>\n",
       "      <td>40.815413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.423393</td>\n",
       "      <td>0.377644</td>\n",
       "      <td>0.422928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>3</td>\n",
       "      <td>43.435521</td>\n",
       "      <td>-0.021245</td>\n",
       "      <td>0.067223</td>\n",
       "      <td>0.025241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>-73.911645</td>\n",
       "      <td>40.804402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.119325</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>3</td>\n",
       "      <td>44.043928</td>\n",
       "      <td>-0.009119</td>\n",
       "      <td>-0.003420</td>\n",
       "      <td>0.027188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Longitude   Latitude  UHI Index  building_cov_100m  building_cov_200m  \\\n",
       "0    -73.971665  40.788763        NaN           0.248892           0.417782   \n",
       "1    -73.971928  40.788875        NaN           0.167185           0.401631   \n",
       "2    -73.967080  40.789080        NaN           0.685125           0.469204   \n",
       "3    -73.972550  40.789082        NaN           0.505082           0.524747   \n",
       "4    -73.969697  40.787953        NaN           0.576894           0.712504   \n",
       "...         ...        ...        ...                ...                ...   \n",
       "1035 -73.919388  40.813803        NaN           0.374859           0.371426   \n",
       "1036 -73.931033  40.833178        NaN           0.119606           0.250616   \n",
       "1037 -73.934647  40.854542        NaN           0.215837           0.468919   \n",
       "1038 -73.917223  40.815413        NaN           0.423393           0.377644   \n",
       "1039 -73.911645  40.804402        NaN           0.020119           0.005607   \n",
       "\n",
       "      building_cov_500m  park_cov_1000m  water_cov_1000m  \\\n",
       "0              0.434283        0.022609         0.000000   \n",
       "1              0.434841        0.023426         0.000000   \n",
       "2              0.393609        0.402937         0.094989   \n",
       "3              0.419828        0.018978         0.000000   \n",
       "4              0.645928        0.161423         0.000054   \n",
       "...                 ...             ...              ...   \n",
       "1035           0.425470        0.017420         0.000000   \n",
       "1036           0.235188        0.024506         0.110873   \n",
       "1037           0.400809        0.026099         0.000000   \n",
       "1038           0.422928        0.000000         0.000000   \n",
       "1039           0.119325        0.017591         0.000000   \n",
       "\n",
       "      street_tree_cov_500m  location_cluster  lst_value  ndvi_value  \\\n",
       "0                 0.002833                 5  40.178148   -0.051394   \n",
       "1                 0.002616                 5  40.178148   -0.039764   \n",
       "2                 0.001872                 5  38.168352   -0.044698   \n",
       "3                 0.002479                 5  40.311450   -0.012213   \n",
       "4                 0.002761                 5  38.130754   -0.025760   \n",
       "...                    ...               ...        ...         ...   \n",
       "1035              0.001819                 3  44.901851   -0.076566   \n",
       "1036              0.001466                 6  39.904706   -0.018511   \n",
       "1037              0.001841                 9  41.237734    0.072678   \n",
       "1038              0.001072                 3  43.435521   -0.021245   \n",
       "1039              0.000768                 3  44.043928   -0.009119   \n",
       "\n",
       "      ndbi_value  ndwi_value  \n",
       "0      -0.025287    0.058137  \n",
       "1      -0.039936    0.046170  \n",
       "2       0.024026    0.049971  \n",
       "3      -0.059256    0.040509  \n",
       "4      -0.075313    0.039932  \n",
       "...          ...         ...  \n",
       "1035    0.301264    0.040039  \n",
       "1036   -0.066043    0.035125  \n",
       "1037   -0.054582   -0.068365  \n",
       "1038    0.067223    0.025241  \n",
       "1039   -0.003420    0.027188  \n",
       "\n",
       "[1040 rows x 14 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99f3a93f-6c2b-45e7-9995-3eb039fe7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Models:\n",
      " [('RandomForest', RandomForestRegressor(bootstrap=False, max_depth=30, max_features='sqrt',\n",
      "                      min_samples_leaf=2, min_samples_split=3, n_estimators=600,\n",
      "                      random_state=42)), ('ExtraTrees', ExtraTreesRegressor(max_depth=25, min_samples_leaf=3, min_samples_split=10,\n",
      "                    n_estimators=300, random_state=42)), ('CatBoost', <catboost.core.CatBoostRegressor object at 0x7f90990b3d90>)]\n"
     ]
    }
   ],
   "source": [
    "# 1) Identify top N from results_df\n",
    "topN = results_df.head(3).reset_index(drop=True)  # e.g. top 3\n",
    "base_models = []\n",
    "for i in range(len(topN)):\n",
    "    model_name = topN.loc[i, \"Model\"]\n",
    "    estimator = topN.loc[i, \"Best Estimator\"]\n",
    "    base_models.append((model_name, estimator))\n",
    "\n",
    "print(\"\\nTop Models:\\n\", base_models)\n",
    "modelA, modelB, modelC = base_models[0][1], base_models[1][1], base_models[2][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1131161d-6398-4db9-9d3c-be4464927c6a",
   "metadata": {},
   "source": [
    "### WEIGHTED SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "173166b1-80d7-4f36-b825-a1305b0ab81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_ensemble_weights_2(modelA, modelB, X, y, skf, increments=0.01):\n",
    "    predsA_oof = np.zeros(len(X))\n",
    "    predsB_oof = np.zeros(len(X))\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(X, y_bins):\n",
    "        XA, XV = X[train_idx], X[valid_idx]\n",
    "        ya, yv = y[train_idx], y[valid_idx]\n",
    "        mA = clone(modelA); mB = clone(modelB)\n",
    "        mA.fit(XA, ya); mB.fit(XA, ya)\n",
    "        predsA_oof[valid_idx] = mA.predict(XV)\n",
    "        predsB_oof[valid_idx] = mB.predict(XV)\n",
    "\n",
    "    best_w, best_r2 = 0, -999\n",
    "    for w1 in np.arange(0, 1.0 + increments, increments):\n",
    "        blend = w1 * predsA_oof + (1-w1) * predsB_oof\n",
    "        r2_ens = r2_score(y, blend)\n",
    "        if r2_ens > best_r2:\n",
    "            best_r2 = r2_ens\n",
    "            best_w = w1\n",
    "    return best_w, best_r2\n",
    "\n",
    "def search_ensemble_weights_3(modelA, modelB, modelC, X, y, skf, increments=0.01):\n",
    "    predsA_oof = np.zeros(len(X))\n",
    "    predsB_oof = np.zeros(len(X))\n",
    "    predsC_oof = np.zeros(len(X))\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(X, y_bins):\n",
    "        XA, XV = X[train_idx], X[valid_idx]\n",
    "        ya, yv = y[train_idx], y[valid_idx]\n",
    "        clone(modelA).fit(XA, ya)\n",
    "        clone(modelB).fit(XA, ya)\n",
    "        clone(modelC).fit(XA, ya)\n",
    "\n",
    "        predsA_oof[valid_idx] = modelA.predict(XV)\n",
    "        predsB_oof[valid_idx] = modelB.predict(XV)\n",
    "        predsC_oof[valid_idx] = modelC.predict(XV)\n",
    "\n",
    "    best_combo, best_r2 = (0,0,0), -999\n",
    "    for w1 in np.arange(0,1+increments,increments):\n",
    "        for w2 in np.arange(0,1+increments,increments):\n",
    "            w3 = 1 - w1 - w2\n",
    "            if w3 < 0: continue\n",
    "            blend = w1*predsA_oof + w2*predsB_oof + w3*predsC_oof\n",
    "            r2_ens = r2_score(y, blend)\n",
    "            if r2_ens > best_r2:\n",
    "                best_r2 = r2_ens\n",
    "                best_combo = (w1,w2,w3)\n",
    "    return best_combo, best_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "243f218e-09b6-49ae-899b-2260890f0c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3-model weights => w1=1.000, w2=0.000, w3=0.000; OOF R^2=0.99721\n",
      "Saved 3-model weighted ensemble.\n"
     ]
    }
   ],
   "source": [
    "# Weighted 3-model ensemble with finer increments\n",
    "best_combo, best_r2 = search_ensemble_weights_3(modelA, modelB, modelC, X, y, skf, increments=0.01)\n",
    "w1, w2, w3 = best_combo\n",
    "print(f\"Best 3-model weights => w1={w1:.3f}, w2={w2:.3f}, w3={w3:.3f}; OOF R^2={best_r2:.5f}\")\n",
    "\n",
    "# Refit all on full data\n",
    "finalA = clone(modelA).fit(X, y)\n",
    "finalB = clone(modelB).fit(X, y)\n",
    "finalC = clone(modelC).fit(X, y)\n",
    "\n",
    "predA_val = finalA.predict(X_val)\n",
    "predB_val = finalB.predict(X_val)\n",
    "predC_val = finalC.predict(X_val)\n",
    "\n",
    "final_ensemble_val = w1 * predA_val + w2 * predB_val + w3 * predC_val\n",
    "df_val[\"UHI Index\"] = final_ensemble_val\n",
    "\n",
    "# Create a submission DataFrame with only the required columns\n",
    "submission = df_val[[\"Longitude\", \"Latitude\", \"UHI Index\"]]\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "submission.to_csv(\"output/submission_v14_3model_weighted.csv\", index=False)\n",
    "print(\"Saved 3-model weighted ensemble.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6cda64-f7ea-4e02-bed8-ea9c92739ce1",
   "metadata": {},
   "source": [
    "### SAVE THE WEIGHTED ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4710fde-1aac-474f-a2b3-eea9ed87dc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3-model weighted ensemble with discovered weights.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "final_ensemble_dict = {\n",
    "    \"model_names\": [\"ModelA\",\"ModelB\",\"ModelC\"],\n",
    "    \"models\": [finalA, finalB, finalC],\n",
    "    \"weights\": (w1,w2,w3)\n",
    "}\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "with open(\"models/3model_weighted_ensemble_v14.pkl\",\"wb\") as f:\n",
    "    pickle.dump(final_ensemble_dict, f)\n",
    "print(\"Saved 3-model weighted ensemble with discovered weights.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c431b-0266-41e0-b702-8750fe7f7bdd",
   "metadata": {},
   "source": [
    "### SIMPLE ENSEMBLE WITH AVERAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b7e1706-c8b0-443e-bb56-63520559f39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission for average ensemble\n",
      "Saved submission for average ensemble\n",
      "Saved submission for average ensemble\n"
     ]
    }
   ],
   "source": [
    "val_predsA = modelA.predict(X_val)\n",
    "val_predsB = modelB.predict(X_val)\n",
    "val_predsC = modelC.predict(X_val)\n",
    "ensemble_preds_3 = (val_predsA + val_predsB + val_predsC) / 3\n",
    "ensemble_preds_2 = (val_predsA + val_predsB) / 2\n",
    "\n",
    "# Add predictions to the validation dataframe\n",
    "df_val[\"UHI Index\"] = ensemble_preds_3\n",
    "submission = df_val[[\"Longitude\", \"Latitude\", \"UHI Index\"]]\n",
    "\n",
    "# Save the submission\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "submission.to_csv(\"output/submission_v14-avg3.csv\", index=False)\n",
    "print(\"Saved submission for average ensemble\")\n",
    "\n",
    "df_val[\"UHI Index\"] = ensemble_preds_2\n",
    "submission = df_val[[\"Longitude\", \"Latitude\", \"UHI Index\"]]\n",
    "\n",
    "# Save the submission\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "submission.to_csv(\"output/submission_v14-avg2.csv\", index=False)\n",
    "print(\"Saved submission for average ensemble\")\n",
    "\n",
    "df_val[\"UHI Index\"] = val_predsA\n",
    "submission = df_val[[\"Longitude\", \"Latitude\", \"UHI Index\"]]\n",
    "\n",
    "# Save the submission\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "submission.to_csv(\"output/submission_v14.csv\", index=False)\n",
    "print(\"Saved submission for average ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adee3b6a-bede-450d-9a28-3cf72ec15d25",
   "metadata": {},
   "source": [
    "### OUT-OF-FOLD PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "855bd8f1-872b-4038-b30f-f0837d9b603b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: RandomForest; RandomForestRegressor(bootstrap=False, max_depth=30, max_features='sqrt',\n",
      "                      min_samples_leaf=2, min_samples_split=3, n_estimators=600,\n",
      "                      random_state=42)\n",
      "\t[    0     2     3 ... 11265 11266 11267], [    1    11    17 ... 11252 11263 11268]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [    8    21    22 ... 11254 11259 11260]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [   19    25    28 ... 11231 11233 11261]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [   33    59    72 ... 11209 11248 11264]\n",
      "\t[    0     1     3 ... 11266 11267 11268], [    2     6    13 ... 11228 11235 11257]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [   10    24    49 ... 11210 11223 11241]\n",
      "\t[    0     1     2 ... 11265 11267 11268], [    3     4     7 ... 11238 11249 11266]\n",
      "\t[    0     1     2 ... 11264 11266 11268], [    5    18    34 ... 11253 11265 11267]\n",
      "\t[    1     2     3 ... 11266 11267 11268], [    0     9    38 ... 11242 11246 11258]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [   12    30    31 ... 11255 11256 11262]\n",
      "1: ExtraTrees; ExtraTreesRegressor(max_depth=25, min_samples_leaf=3, min_samples_split=10,\n",
      "                    n_estimators=300, random_state=42)\n",
      "\t[    0     2     3 ... 11265 11266 11267], [    1    11    17 ... 11252 11263 11268]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [    8    21    22 ... 11254 11259 11260]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [   19    25    28 ... 11231 11233 11261]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [   33    59    72 ... 11209 11248 11264]\n",
      "\t[    0     1     3 ... 11266 11267 11268], [    2     6    13 ... 11228 11235 11257]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [   10    24    49 ... 11210 11223 11241]\n",
      "\t[    0     1     2 ... 11265 11267 11268], [    3     4     7 ... 11238 11249 11266]\n",
      "\t[    0     1     2 ... 11264 11266 11268], [    5    18    34 ... 11253 11265 11267]\n",
      "\t[    1     2     3 ... 11266 11267 11268], [    0     9    38 ... 11242 11246 11258]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [   12    30    31 ... 11255 11256 11262]\n",
      "2: CatBoost; <catboost.core.CatBoostRegressor object at 0x7f90990b3d90>\n",
      "\t[    0     2     3 ... 11265 11266 11267], [    1    11    17 ... 11252 11263 11268]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [    8    21    22 ... 11254 11259 11260]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [   19    25    28 ... 11231 11233 11261]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [   33    59    72 ... 11209 11248 11264]\n",
      "\t[    0     1     3 ... 11266 11267 11268], [    2     6    13 ... 11228 11235 11257]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [   10    24    49 ... 11210 11223 11241]\n",
      "\t[    0     1     2 ... 11265 11267 11268], [    3     4     7 ... 11238 11249 11266]\n",
      "\t[    0     1     2 ... 11264 11266 11268], [    5    18    34 ... 11253 11265 11267]\n",
      "\t[    1     2     3 ... 11266 11267 11268], [    0     9    38 ... 11242 11246 11258]\n",
      "\t[    0     1     2 ... 11266 11267 11268], [   12    30    31 ... 11255 11256 11262]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.01642201, 1.01684682, 1.01318253],\n",
       "       [1.02025508, 1.02117015, 1.01917202],\n",
       "       [1.02408301, 1.02241886, 1.02439831],\n",
       "       ...,\n",
       "       [0.97753032, 0.97830715, 0.97576247],\n",
       "       [0.98239024, 0.98038406, 0.98117287],\n",
       "       [0.98140884, 0.97933213, 0.98036391]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do a custom out-of-fold prediction approach for these top 3\n",
    "\n",
    "# A) Generate OOF predictions for each base model\n",
    "#    We'll create arrays of shape [n_samples, n_base_models]\n",
    "oof_preds = np.zeros((len(X), len(base_models)))\n",
    "\n",
    "for idx, (mname, base_model) in enumerate(base_models):\n",
    "    print(f\"{idx}: {mname}; {base_model}\")\n",
    "    # We'll do a new copy of the model so we don't re-fit the original\n",
    "    # or we can clone it\n",
    "    model_clone = clone(base_model)\n",
    "\n",
    "    # out-of-fold predictions\n",
    "    fold_idx = 0\n",
    "    for train_idx, valid_idx in skf.split(X, y_bins):\n",
    "        print(f\"\\t{train_idx}, {valid_idx}\")\n",
    "        X_trainF, X_validF = X[train_idx], X[valid_idx]\n",
    "        y_trainF, y_validF = y[train_idx], y[valid_idx]\n",
    "\n",
    "        model_clone.fit(X_trainF, y_trainF)\n",
    "        preds_validF = model_clone.predict(X_validF)\n",
    "        oof_preds[valid_idx, idx] = preds_validF\n",
    "\n",
    "oof_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef2b6e-7925-47ee-b53a-87d83fe0688c",
   "metadata": {},
   "source": [
    "### META-LEARNERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54ffc5e0-5e3a-45a1-9fba-7d8cfb431cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Meta-Learner Comparison ===\n",
      "XGB => OOF R2: 0.98220\n",
      "RF => OOF R2: 0.98018\n",
      "LightGBM => OOF R2: 0.96387\n",
      "Linear => OOF R2: 0.94269\n",
      "Ridge => OOF R2: 0.94269\n",
      "Lasso => OOF R2: 0.94269\n",
      "MLP => OOF R2: 0.92740\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(oof_preds)\n",
    "X_stacked= np.hstack([oof_preds, X])\n",
    "\n",
    "meta_learners = {\n",
    "    \"Linear\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=RANDOM_SEED),\n",
    "    \"Lasso\": Lasso(alpha=1e-5, random_state=RANDOM_SEED),\n",
    "    \"XGB\": xgb.XGBRegressor(n_estimators=100, learning_rate=0.05,\n",
    "                            max_depth=15, random_state=RANDOM_SEED, \n",
    "                            subsample=0.9, colsample_bytree=0.9,\n",
    "                            eval_metric=\"rmse\", use_label_encoder=False,\n",
    "                            tree_method=\"gpu_hist\", predictor=\"gpu_predictor\"),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(n_estimators=400, learning_rate=0.05, \n",
    "                                  min_child_samples=1, num_leaves=31,\n",
    "                                  max_depth=None, random_state=RANDOM_SEED,\n",
    "                                  device='gpu'),\n",
    "    \"RF\": RandomForestRegressor(n_estimators=500, max_depth=None,\n",
    "                                min_samples_split=4, min_samples_leaf=2, \n",
    "                                max_features=0.5, random_state=RANDOM_SEED),\n",
    "    \"MLP\": MLPRegressor(hidden_layer_sizes=(256,128), activation=\"relu\",\n",
    "                        solver=\"adam\", max_iter=500, random_state=RANDOM_SEED)\n",
    "}\n",
    "\n",
    "# We'll store results in a dict\n",
    "meta_results = {}\n",
    "\n",
    "for mname, meta_model in meta_learners.items():\n",
    "    # Fit on the entire training set (oof_preds => y)\n",
    "    meta_model.fit(X_scaled, y)\n",
    "    \n",
    "    # Evaluate OOF RÂ² on the *same* data used for training\n",
    "    # (some risk of overfitting, but a quick comparison is fine)\n",
    "    preds_oof = meta_model.predict(X_scaled)\n",
    "    r2_val = r2_score(y, preds_oof)\n",
    "    \n",
    "    meta_results[mname] = r2_val\n",
    "\n",
    "# Print each meta-learnerâ€™s OOF RÂ²\n",
    "print(\"=== Meta-Learner Comparison ===\")\n",
    "for mname, score in sorted(meta_results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{mname} => OOF R2: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0ffd98c-f754-4443-878d-6d7c4c34c1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best meta-learner: XGB, OOF R2 => 0.98220\n",
      "0: RandomForest, RandomForestRegressor(bootstrap=False, max_depth=30, max_features='sqrt',\n",
      "                      min_samples_leaf=2, min_samples_split=3, n_estimators=600,\n",
      "                      random_state=42)\n",
      "1: ExtraTrees, ExtraTreesRegressor(max_depth=25, min_samples_leaf=3, min_samples_split=10,\n",
      "                    n_estimators=300, random_state=42)\n",
      "2: CatBoost, <catboost.core.CatBoostRegressor object at 0x7f90990b3d90>\n",
      "Refitted best meta-learner (XGB) on entire dataset.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "# Suppose you have:\n",
    "# base_models = [(name1, model1), (name2, model2), ...]\n",
    "# meta_learners = { \"LightGBM\": best_LGB, \"XGB\": best_XGB, ... } from your previous cell\n",
    "# meta_results = { \"LightGBM\": 0.99822, \"XGB\": 0.98399, ... } mapping each meta-learner to an OOF RÂ²\n",
    "# scaler = StandardScaler() # previously fit on oof_preds\n",
    "# X, y => full training data\n",
    "# oof_preds => shape (n_samples, len(base_models))\n",
    "\n",
    "##############################################\n",
    "# 1) Identify the best meta-learner from OOF\n",
    "##############################################\n",
    "best_meta_name = max(meta_results, key=meta_results.get)\n",
    "best_meta_model = meta_learners[best_meta_name]\n",
    "print(f\"Best meta-learner: {best_meta_name}, OOF R2 => {meta_results[best_meta_name]:.5f}\")\n",
    "\n",
    "##############################################\n",
    "# 2) Refit each base model on the FULL data\n",
    "##############################################\n",
    "base_models_fitted = []\n",
    "full_preds_stack = np.zeros((len(X), len(base_models)))  # same shape logic as OOF, but now for entire data\n",
    "\n",
    "for idx, (mname, base_model) in enumerate(base_models):\n",
    "    print(f\"{idx}: {mname}, {base_model}\")\n",
    "    # clone to avoid reusing partial state\n",
    "    fm = clone(base_model)\n",
    "    fm.fit(X, y)\n",
    "    base_models_fitted.append((mname, fm))\n",
    "    # store predictions\n",
    "    full_preds_stack[:, idx] = fm.predict(X)\n",
    "\n",
    "##############################################\n",
    "# 3) Scale the stacked predictions\n",
    "##############################################\n",
    "full_preds_stack_scaled = scaler.transform(full_preds_stack)\n",
    "\n",
    "##############################################\n",
    "# 4) Refit the chosen meta-learner on FULL stack\n",
    "##############################################\n",
    "final_meta_learner = clone(best_meta_model)\n",
    "final_meta_learner.fit(full_preds_stack_scaled, y)\n",
    "\n",
    "print(f\"Refitted best meta-learner ({best_meta_name}) on entire dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6382ead5-0714-47e1-8075-f0768acca691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9913063 , 0.9921562 , 0.98269475, ..., 0.9902654 , 0.998148  ,\n",
       "       0.9912577 ], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAKE VALIDATION PREDICTIONS via meta-ensemble\n",
    "\n",
    "# 1) Stack predictions from each base model\n",
    "val_stack = np.zeros((len(X_val), len(base_models_fitted)))\n",
    "for idx, (mname, fm) in enumerate(base_models_fitted):\n",
    "    val_stack[:, idx] = fm.predict(X_val)\n",
    "\n",
    "# 2) Scale the stacked predictions, using the same scaler fit on OOF\n",
    "val_stack_scaled = scaler.transform(val_stack)\n",
    "\n",
    "# 3) Meta-learner final predictions\n",
    "final_val_preds = final_meta_learner.predict(val_stack_scaled)\n",
    "final_val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1617e948-7124-4fd3-820c-2de28307698c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output/submission_v14_meta.csv\n"
     ]
    }
   ],
   "source": [
    "# SAVE SUBMISSION\n",
    "# df_val = pd.read_csv(\"./data/Submission_template_UHI2025-v2.csv\")\n",
    "df_val[\"UHI Index\"] = final_val_preds\n",
    "submission = df_val[[\"Longitude\", \"Latitude\", \"UHI Index\"]]\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "submission_path = \"output/submission_v14_meta.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Saved {submission_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7920351-9cf5-4fa8-ac1a-919981bf47c7",
   "metadata": {},
   "source": [
    "### TWEAK MODEL APPOACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8c9b064-e43b-473f-9940-eee8416e421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output/submission_v14_tweak_3model.csv\n"
     ]
    }
   ],
   "source": [
    "# We'll do a 3-model OOF to confirm final ensemble => then tweak\n",
    "predsA_oof = np.zeros(len(X))\n",
    "predsB_oof = np.zeros(len(X))\n",
    "predsC_oof = np.zeros(len(X))\n",
    "\n",
    "for train_idx, valid_idx in skf.split(X,y_bins):\n",
    "    XA, XV = X[train_idx], X[valid_idx]\n",
    "    ya, yv = y[train_idx], y[valid_idx]\n",
    "    \n",
    "    foldA = clone(modelA).fit(XA, ya)\n",
    "    foldB = clone(modelB).fit(XA, ya)\n",
    "    foldC = clone(modelC).fit(XA, ya)\n",
    "\n",
    "    predsA_oof[valid_idx] = foldA.predict(XV)\n",
    "    predsB_oof[valid_idx] = foldB.predict(XV)\n",
    "    predsC_oof[valid_idx] = foldC.predict(XV)\n",
    "\n",
    "# wA, wB, wC = (0.3,0.4,0.3)  # or from search_ensemble_weights_3\n",
    "ensemble_oof = w1*predsA_oof + w2*predsB_oof + w3*predsC_oof\n",
    "residual_oof = y - ensemble_oof\n",
    "\n",
    "# Tweak model:\n",
    "tweak_model = DecisionTreeRegressor(max_depth=4).fit(X, residual_oof)\n",
    "\n",
    "# Full-data refit\n",
    "finalA = clone(modelA).fit(X,y)\n",
    "finalB = clone(modelB).fit(X,y)\n",
    "finalC = clone(modelC).fit(X,y)\n",
    "\n",
    "predA_val = finalA.predict(X_val)\n",
    "predB_val = finalB.predict(X_val)\n",
    "predC_val = finalC.predict(X_val)\n",
    "\n",
    "ensemble_val = w1*predA_val + w2*predB_val + w3*predC_val\n",
    "residual_val = tweak_model.predict(X_val)\n",
    "final_pred = ensemble_val + residual_val\n",
    "\n",
    "df_val[\"UHI Index\"] = final_pred\n",
    "submission = df_val[[\"Longitude\", \"Latitude\", \"UHI Index\"]]\n",
    "submission_path = \"output/submission_v14_tweak_3model.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Saved {submission_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc796ce-066c-4f00-9fea-02d245399559",
   "metadata": {},
   "source": [
    "### SAVE TOP MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38828f6e-43b5-4aeb-a974-b32d3d94d5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved base model: models/base_RandomForest_model_0_v14.pkl\n",
      "Saved base model: models/base_ExtraTrees_model_1_v14.pkl\n",
      "Saved base model: models/base_CatBoost_model_2_v14.pkl\n",
      "Saved final meta-learner (XGB) => models/final_meta_learner_XGB_20250208_1757.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save each base model\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "for i, (mname, fm) in enumerate(base_models_fitted):\n",
    "    output_path = f\"models/base_{mname}_model_{i}_v14.pkl\"\n",
    "    dump(fm, output_path)\n",
    "    print(f\"Saved base model: {output_path}\")\n",
    "\n",
    "# Save final meta-learner\n",
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "meta_output_path = f\"models/final_meta_learner_{best_meta_name}_{timestamp}.pkl\"SS\n",
    "dump(final_meta_learner, meta_output_path)\n",
    "print(f\"Saved final meta-learner ({best_meta_name}) => {meta_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
